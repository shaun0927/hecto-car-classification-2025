{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0956aa0b",
   "metadata": {},
   "source": [
    "셀0 : 패키지 설치 및 conda 환경설정\n",
    "\n",
    "# 콘다 프롬프트(터미널)에서 실행\n",
    "conda create -n hecto_car python=3.10 -y\n",
    "conda activate hecto_car\n",
    "\n",
    "# Jupyter 노트북 커널 연결용 ipykernel 설치\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name hecto_car --display-name \"hecto_car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0beb3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 셀 0 ─ Windows 호환 패키지 설치\n",
    "# import sys, subprocess, re, importlib, platform\n",
    "\n",
    "# INSTALL_FAISS_GPU = False   # ← GPU 버전 쓰려면 True 로 바꾸고 conda 사용\n",
    "\n",
    "# def clean(pkg): return re.split(r'[<=>]', pkg)[0]\n",
    "\n",
    "# def pip_install(pkg):\n",
    "#     subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"--quiet\"])\n",
    "\n",
    "# required = [\n",
    "#     \"timm>=0.9.12\",\n",
    "#     \"albumentations>=1.4.0\",\n",
    "#     \"einops>=0.7.0\",\n",
    "#     \"pandas\",\n",
    "#     \"scikit-learn\",\n",
    "#     \"tqdm\",\n",
    "# ]\n",
    "\n",
    "# # 1) 일반 패키지\n",
    "# for p in required:\n",
    "#     name = clean(p)\n",
    "#     if importlib.util.find_spec(name) is None:\n",
    "#         print(\"⏳\", p)\n",
    "#         pip_install(p)\n",
    "#     else:\n",
    "#         print(\"✅\", name, \"already\")\n",
    "\n",
    "# # 2) FAISS 처리\n",
    "# if INSTALL_FAISS_GPU and platform.system() != \"Windows\":\n",
    "#     try:\n",
    "#         pip_install(\"faiss-gpu>=1.7.2\")\n",
    "#     except subprocess.CalledProcessError:\n",
    "#         print(\"⚠️  pip wheel not found, trying conda ...\")\n",
    "#         print(\"run in shell:  conda install -c conda-forge faiss-gpu==1.7.2\")\n",
    "#         raise\n",
    "# else:\n",
    "#     # CPU 버전\n",
    "#     if importlib.util.find_spec(\"faiss\") is None:\n",
    "#         print(\"⏳ installing faiss-cpu\")\n",
    "#         pip_install(\"faiss-cpu>=1.7.2\")\n",
    "#     else:\n",
    "#         print(\"✅ faiss already\")\n",
    "\n",
    "# import torch, timm, albumentations, faiss, einops, pandas, sklearn\n",
    "# print(\"📦  All packages ready — PyTorch\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91826295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧  ROOT  : C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_car_classification\n",
      "🖼️   Train: C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_car_classification\\data\\train\n",
      "🖼️   Test : C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_car_classification\\data\\test\n",
      "🚀  Device: cpu  |  Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# 셀 1 : 기본 경로 설정 & 시드 고정\n",
    "import os, random, numpy as np, torch\n",
    "\n",
    "# 절대 경로 (Windows)\n",
    "ROOT       = r\"C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_car_classification\"\n",
    "TRAIN_DIR  = os.path.join(ROOT, \"data\", \"train\")\n",
    "TEST_DIR   = os.path.join(ROOT, \"data\", \"test\")\n",
    "\n",
    "CFG = dict(\n",
    "    IMG_SIZE = 448,\n",
    "    BATCH    = 32,\n",
    "    EPOCH    = 20,\n",
    "    LR       = 3e-4,\n",
    "    FOLDS    = 5,\n",
    "    SEED     = 42\n",
    ")\n",
    "\n",
    "def seed_everything(seed:int=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "seed_everything(CFG[\"SEED\"])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🔧  ROOT  : {ROOT}\")\n",
    "print(f\"🖼️   Train: {TRAIN_DIR}\")\n",
    "print(f\"🖼️   Test : {TEST_DIR}\")\n",
    "print(f\"🚀  Device: {device}  |  Seed: {CFG['SEED']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f916709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 수 : 33,137  |  클래스 수 : 396\n",
      "Fold 이미지 개수 : {0: 6628, 1: 6628, 2: 6627, 3: 6627, 4: 6627}\n",
      "각 클래스가 모든 fold에 ≥1장 존재?  ➜ Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  label  fold\n",
       "0  C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...      0     4\n",
       "1  C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...      0     0\n",
       "2  C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...      0     4\n",
       "3  C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...      0     1\n",
       "4  C:\\Users\\shaun\\Desktop\\project\\Daycon\\hecto_ca...      0     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 셀 2 : 이미지 경로 -> DataFrame  + Stratified 5-Fold\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "\n",
    "# 1) 폴더명 = 클래스명 목록\n",
    "class_names = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
    "cls2id = {c:i for i,c in enumerate(class_names)}\n",
    "\n",
    "# 2) 모든 이미지 경로 수집\n",
    "records = []\n",
    "for cls in class_names:\n",
    "    cls_dir = os.path.join(TRAIN_DIR, cls)\n",
    "    for fname in os.listdir(cls_dir):\n",
    "        if fname.lower().endswith(\".jpg\"):\n",
    "            records.append([os.path.join(cls_dir, fname), cls2id[cls]])\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"img_path\", \"label\"])\n",
    "print(f\"총 이미지 수 : {len(df):,}  |  클래스 수 : {len(class_names)}\")\n",
    "\n",
    "# 3) Stratified K-Fold split\n",
    "df[\"fold\"] = -1\n",
    "skf = StratifiedKFold(n_splits=CFG[\"FOLDS\"], shuffle=True, random_state=CFG[\"SEED\"])\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(df, df[\"label\"])):\n",
    "    df.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "# 4) 분포 확인\n",
    "fold_sizes = df.groupby(\"fold\").size()\n",
    "cls_min_per_fold = df.groupby([\"fold\",\"label\"]).size().groupby(\"label\").min().min()\n",
    "\n",
    "print(\"Fold 이미지 개수 :\", fold_sizes.to_dict())\n",
    "print(\"각 클래스가 모든 fold에 ≥1장 존재?  ➜\", \"Yes\" if cls_min_per_fold > 0 else \"⚠️  일부 fold에서 사라진 클래스 있음\")\n",
    "\n",
    "# (선택) 희귀 클래스 경고\n",
    "rare = [c for c,cnt in Counter(df[\"label\"]).items() if cnt < 10]\n",
    "if rare:\n",
    "    print(f\"⚠️  샘플 <10장 클래스 {len(rare)}개 → Leave-One-Out 추가 고려\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5092eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Albumentations transforms ready (basic + strong jitter).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaun\\anaconda3\\envs\\hecto_car\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\shaun\\AppData\\Local\\Temp\\ipykernel_23396\\720496036.py:21: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=int(IMG*0.25), max_width=int(IMG*0.25),\n"
     ]
    }
   ],
   "source": [
    "# 셀 3 ─ Albumentations 변형 (모듈 미존재 이슈 없는 최소 + 강 증강)\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD  = [0.229, 0.224, 0.225]\n",
    "IMG  = CFG[\"IMG_SIZE\"]\n",
    "\n",
    "def get_transforms(phase=\"train\"):\n",
    "    if phase == \"train\":\n",
    "        return A.Compose([\n",
    "            # 기본 크롭\n",
    "            A.RandomResizedCrop(size=(IMG, IMG), scale=(0.6, 1.0), ratio=(0.75, 1.333)),\n",
    "            # ── 강증강 대체: ColorJitter or ShiftScaleRotate 중 하나 무조건 적용\n",
    "            A.OneOf([\n",
    "                A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=1.0),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=1.0),\n",
    "            ], p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # 부분 가림\n",
    "            A.CoarseDropout(max_holes=1, max_height=int(IMG*0.25), max_width=int(IMG*0.25),\n",
    "                            min_holes=1, min_height=int(IMG*0.1),  min_width=int(IMG*0.1),\n",
    "                            fill_value=0, p=0.3),\n",
    "            A.Normalize(mean=MEAN, std=STD),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:                           # validation / inference\n",
    "        return A.Compose([\n",
    "            A.Resize(height=IMG, width=IMG),\n",
    "            A.Normalize(mean=MEAN, std=STD),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "train_tf = get_transforms(\"train\")\n",
    "val_tf   = get_transforms(\"val\")\n",
    "print(\"✅ Albumentations transforms ready (basic + strong jitter).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a4aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataLoader ready  |  train=26509  val=6628  classes=396\n"
     ]
    }
   ],
   "source": [
    "# 셀 4 — Custom Dataset + CutMix Collate\n",
    "# --------------------------------------\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CarDataset(Dataset):\n",
    "    \"\"\"\n",
    "    df : pd.DataFrame with columns ['img_path', 'label', 'fold']\n",
    "    transform : Albumentations object (train_tf / val_tf)\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None, is_test=False):\n",
    "        self.paths = df[\"img_path\"].tolist()\n",
    "        self.labels = None if is_test else df[\"label\"].tolist()\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)[\"image\"]  # returns torch.Tensor [C,H,W]\n",
    "\n",
    "        if self.is_test:\n",
    "            return img, self.paths[idx]               # path 보존\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "\n",
    "\n",
    "# ---------- CutMix Collate --------------------------------------------------\n",
    "def rand_bbox(W, H, lam):\n",
    "    \"\"\"returns bbx1, bby1, bbx2, bby2\"\"\"\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
    "    # uniform center\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def get_cutmix_collate(n_classes, alpha=1.0, prob=0.5):\n",
    "    \"\"\"\n",
    "    factory → DataLoader(collate_fn=...) 로 넘긴다\n",
    "    labels → soft-target one-hot Tensor (B, n_classes)\n",
    "    \"\"\"\n",
    "    def _collate(batch):\n",
    "        imgs, labels = list(zip(*batch))\n",
    "        imgs = torch.stack(imgs)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        onehot = torch.zeros(imgs.size(0), n_classes, dtype=torch.float32)\n",
    "        onehot.scatter_(1, labels.view(-1, 1), 1.0)\n",
    "\n",
    "        if np.random.rand() < prob:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "            rand_idx = torch.randperm(imgs.size(0))\n",
    "            shuffled_imgs = imgs[rand_idx]\n",
    "            shuffled_onehot = onehot[rand_idx]\n",
    "\n",
    "            _, H, W = imgs.shape[1:]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(W, H, lam)\n",
    "\n",
    "            imgs[:, :, bby1:bby2, bbx1:bbx2] = shuffled_imgs[:, :, bby1:bby2, bbx1:bbx2]\n",
    "            lam_adj = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "            onehot = onehot * lam_adj + shuffled_onehot * (1. - lam_adj)\n",
    "\n",
    "        return imgs, onehot\n",
    "    return _collate\n",
    "\n",
    "\n",
    "# ---------- DataLoader 예시 (train / val) -----------------------------------\n",
    "n_classes = len(class_names)  # 셀 2에서 확보\n",
    "\n",
    "train_df = df[df.fold != 0].reset_index(drop=True)   # 예: fold0 를 검증으로\n",
    "val_df   = df[df.fold == 0].reset_index(drop=True)\n",
    "\n",
    "train_set = CarDataset(train_df, transform=train_tf)\n",
    "val_set   = CarDataset(val_df,   transform=val_tf)\n",
    "\n",
    "cutmix_collate = get_cutmix_collate(n_classes, alpha=1.0, prob=0.5)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=CFG[\"BATCH\"],\n",
    "                          shuffle=True, num_workers=4,\n",
    "                          collate_fn=cutmix_collate)\n",
    "\n",
    "val_loader   = DataLoader(val_set, batch_size=CFG[\"BATCH\"],\n",
    "                          shuffle=False, num_workers=4,\n",
    "                          collate_fn=lambda b: (torch.stack([x[0] for x in b]),\n",
    "                                                torch.tensor([x[1] for x in b])))\n",
    "\n",
    "print(f\"✅ DataLoader ready  |  train={len(train_set)}  val={len(val_set)}  classes={n_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7e21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 0  |  train=26509  val=6628  test=8258\n"
     ]
    }
   ],
   "source": [
    "# 셀 5 ─ make_loaders 함수: Fold 인덱스 → train / val / test DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def make_loaders(fold:int,\n",
    "                 df_full,\n",
    "                 batch_size:int = CFG[\"BATCH\"],\n",
    "                 num_workers:int = 4):\n",
    "    \"\"\"\n",
    "    fold : 검증으로 지정할 fold 번호 (0~CFG['FOLDS']-1)\n",
    "    df_full : 셀 2에서 만든 DataFrame (img_path, label, fold)\n",
    "    반환값 : train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    # 1) 분할\n",
    "    train_df = df_full[df_full.fold != fold].reset_index(drop=True)\n",
    "    val_df   = df_full[df_full.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    # 2) Dataset\n",
    "    train_set = CarDataset(train_df, transform=train_tf)\n",
    "    val_set   = CarDataset(val_df,   transform=val_tf)\n",
    "    \n",
    "    # 3) Collate\n",
    "    cutmix_fn = get_cutmix_collate(n_classes=len(class_names), alpha=1.0, prob=0.5)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=cutmix_fn\n",
    "    )\n",
    "\n",
    "    # 검증은 CutMix 없음 → 이미지 스택 + 정수 라벨 Tensor\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=lambda batch: (\n",
    "            torch.stack([b[0] for b in batch]),\n",
    "            torch.tensor([b[1] for b in batch])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 4) Test Loader (is_test=True)\n",
    "    test_paths = sorted([os.path.join(TEST_DIR, f)\n",
    "                         for f in os.listdir(TEST_DIR)\n",
    "                         if f.lower().endswith(\".jpg\")])\n",
    "    test_df = pd.DataFrame({\"img_path\": test_paths})\n",
    "    test_set = CarDataset(test_df, transform=val_tf, is_test=True)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=lambda batch: (\n",
    "            torch.stack([b[0] for b in batch]),   # images\n",
    "            [b[1] for b in batch]                 # img_path list (ID)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"📊 Fold {fold}  |  train={len(train_set)}  val={len(val_set)}  test={len(test_set)}\")\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 예시: fold 0 로더 생성\n",
    "train_loader, val_loader, test_loader = make_loaders(fold=0, df_full=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ded7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized – ConvNeXt-B + GeM + Sub-center ArcFace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaun\\anaconda3\\envs\\hecto_car\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shaun\\.cache\\huggingface\\hub\\models--timm--convnext_base.fb_in22k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# 셀 6 ─ GeM + Sub-center ArcFace Head\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "from einops import rearrange\n",
    "\n",
    "# ---------------- GeM Pool ---------------------------------------------------\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p: float = 3.0, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.p   = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (B,C,H,W)\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p),\n",
    "                            kernel_size=(x.size(-2), x.size(-1))\n",
    "                           ).pow(1.0 / self.p).flatten(1)\n",
    "\n",
    "# ---------------- Sub-center ArcFace ----------------------------------------\n",
    "class SubCenterArcFace(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Sub-center ArcFace\n",
    "    * in_features  : backbone feature dim\n",
    "    * out_classes  : number of classes\n",
    "    * k            : sub-centers per class\n",
    "    * s            : scale factor (logits = cos * s)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, out_classes: int, k: int = 3, s: float = 30.0):\n",
    "        super().__init__()\n",
    "        self.out_classes = out_classes\n",
    "        self.k           = k\n",
    "        self.s           = s\n",
    "\n",
    "        # weight shape : [out_classes * k, in_features]\n",
    "        self.weight = nn.Parameter(torch.randn(out_classes * k, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x  : (B, in_features)        – assume already flattened\n",
    "        x = F.normalize(x, dim=1)\n",
    "        W = F.normalize(self.weight, dim=1)\n",
    "\n",
    "        # cosine sim: (B, out_classes * k)\n",
    "        cos = F.linear(x, W)\n",
    "\n",
    "        # reshape to (B, classes, k)  → 최대 sub-center 선택\n",
    "        cos = rearrange(cos, \"b (c k) -> b c k\", c=self.out_classes, k=self.k)\n",
    "        cos_max, _ = torch.max(cos, dim=2)          # (B, classes)\n",
    "\n",
    "        logits = cos_max * self.s\n",
    "        return logits\n",
    "\n",
    "# ---------------- Backbone + Head -------------------------------------------\n",
    "class CarNet(nn.Module):\n",
    "    def __init__(self, n_classes: int, k: int = 3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            \"convnext_base\", pretrained=True, num_classes=0   # feature only\n",
    "        )\n",
    "        in_dim = self.backbone.num_features\n",
    "        self.pool = GeM(p=3)\n",
    "        self.head = SubCenterArcFace(in_dim, n_classes, k=k, s=30.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone.forward_features(x)    # (B,C,H,W)\n",
    "        feat = self.pool(feat)                      # (B,C)\n",
    "        logits = self.head(feat)                    # (B, n_classes)\n",
    "        return logits\n",
    "\n",
    "# 예시 인스턴스\n",
    "n_classes = len(class_names)       # 396\n",
    "model = CarNet(n_classes=n_classes, k=3).to(device)\n",
    "print(\"✅ Model initialized – ConvNeXt-B + GeM + Sub-center ArcFace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80a98457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training components ready – BCEWithLogitsLoss / AdamW + CosineLR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaun\\AppData\\Local\\Temp\\ipykernel_23396\\3664142599.py:42: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "# 셀 7 ─ 학습 세트업 (Loss · Optim · Scheduler)\n",
    "\n",
    "# 1) 모델 이미 셀 6에서 생성\n",
    "#    model = CarNet(n_classes=len(class_names), k=3).to(device)\n",
    "\n",
    "# 2) Loss   (CutMix → soft one-hot target)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 3) Optimizer\n",
    "#    - Backbone에 기본 LR (3e-4), Head 파라미터에 10× LR\n",
    "def param_groups(model, base_lr, head_lr_mul=10):\n",
    "    backbone, head = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        (head if \"head\" in n else backbone).append(p)\n",
    "    return [\n",
    "        {\"params\": backbone, \"lr\": base_lr},\n",
    "        {\"params\": head,     \"lr\": base_lr * head_lr_mul},\n",
    "    ]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_groups(model, CFG[\"LR\"]),\n",
    "    lr=CFG[\"LR\"],\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "# 4) Scheduler  (Cosine with warm-up 3 epochs)\n",
    "warmup_epochs = 3\n",
    "total_steps   = CFG[\"EPOCH\"] * len(train_loader)\n",
    "warmup_steps  = warmup_epochs * len(train_loader)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / warmup_steps\n",
    "    return 1.0\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# 5) AMP & EMA (선택)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
    "ema_decay = 0.999\n",
    "ema_weights = [p.clone().detach() for p in model.parameters()]\n",
    "\n",
    "print(\"✅ Training components ready – BCEWithLogitsLoss / AdamW + CosineLR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5083f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Train:   0%|          | 0/829 [00:00<?, ?it/s]c:\\Users\\shaun\\anaconda3\\envs\\hecto_car\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# 셀 8 ─ Train / Validate Loop (AMP + Warm-up + EMA)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import math, copy, time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def one_hot(label_tensor, num_cls):\n",
    "    \"\"\"labels(long) -> one-hot(float32)\"\"\"\n",
    "    y = torch.zeros((label_tensor.size(0), num_cls), device=label_tensor.device)\n",
    "    y.scatter_(1, label_tensor.view(-1, 1), 1.0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def update_ema(model, ema_w, decay):\n",
    "    with torch.no_grad():\n",
    "        for p, e in zip(model.parameters(), ema_w):\n",
    "            e.mul_(decay).add_(p.data, alpha=1.0 - decay)\n",
    "\n",
    "\n",
    "best_val_loss = math.inf\n",
    "oof_logits, oof_labels = [], []\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(CFG[\"EPOCH\"]):\n",
    "    # ---------- Train -------------------------------------------------------\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CFG['EPOCH']} Train\", leave=False)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for imgs, soft_targets in pbar:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        soft_targets = soft_targets.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, soft_targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # LR scheduler (warm-up + cosine)\n",
    "        if global_step < warmup_steps:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        global_step += 1\n",
    "\n",
    "        # EMA\n",
    "        update_ema(model, ema_weights, ema_decay)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=f\"{running_loss/ (pbar.n):.4f}\")\n",
    "\n",
    "    # ---------- Validation --------------------------------------------------\n",
    "    model.eval()\n",
    "    val_losses, val_probs, val_lbls = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_loader, desc=\"Valid\", leave=False):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(imgs)\n",
    "            targets = one_hot(labels, n_classes)\n",
    "            loss = criterion(logits, targets)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            val_probs.append(probs)\n",
    "            val_lbls.append(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_probs = np.concatenate(val_probs)\n",
    "    val_lbls  = np.concatenate(val_lbls)\n",
    "    # log_loss expects probabilities for each class (not softmax due to BCE)\n",
    "    val_logloss = log_loss(val_lbls, val_probs, labels=list(range(n_classes)))\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d}  TrainLoss {running_loss/len(train_loader):.4f} |\"\n",
    "          f\" ValLoss {val_loss:.4f} | LogLoss {val_logloss:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if val_logloss < best_val_loss:\n",
    "        best_val_loss = val_logloss\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"ema\":  [w.cpu() for w in ema_weights]},\n",
    "                   f\"{ROOT}\\\\best_model_fold0.pth\")\n",
    "        print(f\"  ✅ best model saved (LogLoss {best_val_loss:.4f})\")\n",
    "\n",
    "    # accumulate OOF for optional later use\n",
    "    oof_logits.append(val_probs)\n",
    "    oof_labels.append(val_lbls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hecto_car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
