{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91826295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 1 : 기본 경로 설정 & 시드 고정\n",
    "import os, random, numpy as np, torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"The number of unique classes is greater than 50% of the number of samples\",\n",
    "    category=UserWarning,\n",
    "    module=r\"sklearn\\.\")     # sklearn 계열 모듈에만 적용\n",
    "\n",
    "# 절대 경로 (Windows)\n",
    "ROOT       = \"/car2\"\n",
    "TRAIN_DIR  = os.path.join(ROOT, \"data\", \"train\")\n",
    "TEST_DIR   = os.path.join(ROOT, \"data\", \"test\")\n",
    "\n",
    "CFG = dict(\n",
    "    # IMG_SIZES = {0:256, 6:384, 12:512, 20:640, 28:768},\n",
    "    IMG_SIZES = {0: 256, 6: 384, 11: 512, 17: 640},\n",
    "    # BATCH_SIZES = {448: 48}, # 해상도별 배치 사이즈\n",
    "    BATCH_SIZES = {256: 224, 384: 96, 512: 48, 640:32, 768:32},\n",
    "    # ★★★ 해상도별 학습률 ★★★\n",
    "    LRS = {256: 4e-5, 384: 8e-5, 512: 6e-5, 640: 2e-5, 768: 8e-6},\n",
    "    EPOCH    = 30,\n",
    "    FT_EPOCHS = 6,\n",
    "    FINAL_IMG_SIZE = 768,\n",
    "    LR       = 4e-5,\n",
    "    FOLDS    = 5,\n",
    "    SEED     = 2025\n",
    ")\n",
    "\n",
    "def seed_everything(seed:int=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "seed_everything(CFG[\"SEED\"])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🔧  ROOT  : {ROOT}\")\n",
    "print(f\"🖼️   Train: {TRAIN_DIR}\")\n",
    "print(f\"🖼️   Test : {TEST_DIR}\")\n",
    "print(f\"🚀  Device: {device}  |  Seed: {CFG['SEED']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f916709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 제외할 파일 목록 --------------------------------------------------\n",
    "EXCLUDE_FILES = {\n",
    "    # 완전 노이즈\n",
    "    \"5시리즈_G60_2024_2025_0010.jpg\",\n",
    "    \"6시리즈_GT_G32_2018_2020_0018.jpg\",\n",
    "    \"7시리즈_G11_2016_2018_0040.jpg\",\n",
    "    \"911_992_2020_2024_0030.jpg\",\n",
    "    \"E_클래스_W212_2010_2016_0022.jpg\",\n",
    "    \"K5_2세대_2016_2018_0007.jpg\",\n",
    "    \"F150_2004_2021_0018.jpg\",\n",
    "    \"G_클래스_W463b_2019_2025_0030.jpg\",\n",
    "    \"GLE_클래스_W167_2019_2024_0068.jpg\",\n",
    "    \"Q5_FY_2021_2024_0032.jpg\",\n",
    "    \"Q30_2017_2019_0075.jpg\",\n",
    "    \"Q50_2014_2017_0031.jpg\",\n",
    "    \"SM7_뉴아트_2008_2011_0053.jpg\",\n",
    "    \"X3_G01_2022_2024_0029.jpg\",\n",
    "    \"XF_X260_2016_2020_0023.jpg\",\n",
    "    \"뉴_ES300h_2013_2015_0000.jpg\",\n",
    "    \"뉴_G80_2025_2026_0042.jpg\", \"뉴_G80_2025_2026_0043.jpg\",\n",
    "    \"뉴_SM5_임프레션_2008_2010_0033.jpg\",\n",
    "    \"더_기아_레이_EV_2024_2025_0078.jpg\",\n",
    "    \"더_뉴_K3_2세대_2022_2024_0001.jpg\",\n",
    "    \"더_뉴_그랜드_스타렉스_2018_2021_0078.jpg\",\n",
    "    \"더_뉴_그랜드_스타렉스_2018_2021_0079.jpg\",\n",
    "    \"더_뉴_그랜드_스타렉스_2018_2021_0080.jpg\",\n",
    "    \"더_뉴_아반떼_2014_2016_0031.jpg\",\n",
    "    \"더_뉴_파사트_2012_2019_0067.jpg\",\n",
    "    \"레니게이드_2019_2023_0041.jpg\",\n",
    "    \"박스터_718_2017_2024_0011.jpg\",\n",
    "    \"싼타페_TM_2019_2020_0009.jpg\",\n",
    "    \"아반떼_MD_2011_2014_0081.jpg\",\n",
    "    \"아반떼_N_2022_2023_0064.jpg\", \"아반떼_N_2022_2023_0035.jpg\",\n",
    "    \"익스플로러_2016_2017_0072.jpg\",\n",
    "    \"콰트로포르테_2017_2022_0074.jpg\",\n",
    "    \"프리우스_4세대_2019_2022_0052.jpg\",\n",
    "    # 차량 내부\n",
    "    \"E_클래스_W212_2010_2016_0069.jpg\",\n",
    "    \"ES300h_7세대_2019_2026_0028.jpg\",\n",
    "    \"G_클래스_W463_2009_2017_0011.jpg\",\n",
    "    \"GLB_클래스_X247_2020_2023_0008.jpg\",\n",
    "    \"GLS_클래스_X167_2020_2024_0013.jpg\",\n",
    "    \"K3_2013_2015_0045.jpg\",\n",
    "    \"K5_3세대_2020_2023_0081.jpg\",\n",
    "    \"Q7_4M_2020_2023_0011.jpg\",\n",
    "    \"RAV4_5세대_2019_2024_0020.jpg\",\n",
    "    \"S_클래스_W223_2021_2025_0008.jpg\", \"S_클래스_W223_2021_2025_0071.jpg\",\n",
    "    \"X4_F26_2015_2018_0068.jpg\",\n",
    "    \"그랜드_체로키_WL_2021_2023_0018.jpg\",\n",
    "    \"레이_2012_2017_0063.jpg\",\n",
    "    \"레인지로버_5세대_2023_2024_0030.jpg\",\n",
    "    \"레인지로버_스포츠_2세대_2018_2022_0014.jpg\", \"레인지로버_스포츠_2세대_2018_2022_0017.jpg\",\n",
    "    \"마칸_2019_2021_0035.jpg\",\n",
    "    \"머스탱_2015_2023_0086.jpg\",\n",
    "    \"아반떼_MD_2011_2014_0009.jpg\", \"아반떼_MD_2011_2014_0082.jpg\",\n",
    "    \"컨티넨탈_GT_3세대_2018_2023_0007.jpg\",\n",
    "    \"타이칸_2021_2025_0065.jpg\",\n",
    "    \"파나메라_2010_2016_0000.jpg\", \"파나메라_2010_2016_0036.jpg\",\n",
    "    \"3시리즈_F30_2013_2018_0036.jpg\",\n",
    "    \"4시리즈_F32_2014_2020_0027.jpg\",\n",
    "    \"5시리즈_G60_2024_2025_0056.jpg\",\n",
    "    \"7시리즈_F01_2009_2015_0029.jpg\", \"7시리즈_F01_2009_2015_0044.jpg\",\n",
    "    \"911_992_2020_2024_0006.jpg\",\n",
    "    \"C_클래스_W204_2008_2015_0068.jpg\",\n",
    "    \"CLS_클래스_C257_2019_2023_0021.jpg\",\n",
    "    # 뒷트렁크 열림\n",
    "    \"Q30_2017_2019_0074.jpg\", \"글래디에이터_JT_2020_2023_0075.jpg\",\n",
    "    \"뉴_CC_2012_2016_0001.jpg\", \"뉴_CC_2012_2016_0002.jpg\",\n",
    "    \"더_뉴_코나_2021_2023_0081.jpg\",\n",
    "    \"2시리즈_액티브_투어러_U06_2022_2024_0004.jpg\",\n",
    "    \"A8_D5_2018_2023_0084.jpg\",\n",
    "}\n",
    "\n",
    "# ---------- Cell-2 : StratifiedKFold (이미지 단위) --------------------\n",
    "import os, hashlib, cv2, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle # 캐싱을 위해 pickle 라이브러리 import\n",
    "from tqdm.auto import tqdm # 진행 상황 확인을 위해 tqdm import\n",
    "\n",
    "# 1) ────────────────────────── ②  중복 검출 해시 함수  ─────────────────\n",
    "def sha1(path: str) -> str:\n",
    "    # 8 ~ 10 ms/장. 충분히 빠릅니다.\n",
    "    with open(path, \"rb\") as f:\n",
    "        return hashlib.sha1(f.read()).hexdigest()\n",
    "\n",
    "TRAIN_DIR = Path(TRAIN_DIR)\n",
    "\n",
    "# 2. 캐시 파일 경로 정의\n",
    "CACHE_PATH = Path(ROOT) / \"hash_cache.pkl\"\n",
    "\n",
    "# 3. 캐시 파일이 있으면 불러오고, 없으면 생성\n",
    "if CACHE_PATH.exists():\n",
    "    print(f\"✅ Loading hash cache from: {CACHE_PATH}\")\n",
    "    with open(CACHE_PATH, \"rb\") as f:\n",
    "        path_to_hash = pickle.load(f)\n",
    "else:\n",
    "    print(f\"⚠️ Hash cache not found. Creating a new one... (This will take a minute)\")\n",
    "    path_to_hash = {}\n",
    "    # 전체 이미지 경로를 미리 수집\n",
    "    all_img_paths = list(TRAIN_DIR.glob(\"**/*.jpg\"))\n",
    "    for img_path in tqdm(all_img_paths, desc=\"Computing Hashes\"):\n",
    "        path_to_hash[str(img_path)] = sha1(img_path)\n",
    "\n",
    "    # 다음 실행을 위해 캐시 파일 저장\n",
    "    with open(CACHE_PATH, \"wb\") as f:\n",
    "        pickle.dump(path_to_hash, f)\n",
    "    print(f\"✅ Hash cache created and saved to: {CACHE_PATH}\")\n",
    "\n",
    "# 2) (alias 반영된) 클래스 목록 구축\n",
    "class_names    = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])\n",
    "cls2id        = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "records, seen_hash = [], set()\n",
    "\n",
    "# 디스크를 다시 읽는 대신, 미리 계산된 해시 딕셔너리를 사용\n",
    "for img_path_str, h in tqdm(path_to_hash.items(), desc=\"Filtering Duplicates\"):\n",
    "    img_path = Path(img_path_str)\n",
    "\n",
    "    if img_path.name in EXCLUDE_FILES:\n",
    "        continue\n",
    "\n",
    "    if h in seen_hash:\n",
    "        continue\n",
    "    seen_hash.add(h)\n",
    "\n",
    "    # 파일 경로에서 클래스 이름(폴더명)을 추출\n",
    "    class_name = img_path.parent.name\n",
    "    records.append([img_path_str, cls2id[class_name]])\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"img_path\", \"label\"])\n",
    "print(f\"#images {len(df):,} | #classes {len(class_names)}\")\n",
    "\n",
    "# 3) StratifiedKFold ----------------------------------------------------\n",
    "df[\"fold\"] = -1\n",
    "skf = StratifiedKFold(n_splits=CFG[\"FOLDS\"], shuffle=True,\n",
    "                      random_state=CFG[\"SEED\"])\n",
    "for fold, (_, val_idx) in enumerate(skf.split(df, y=df[\"label\"])):\n",
    "    df.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "print(\"\\n◆ per-class 이미지 수 by fold\")\n",
    "print(df.groupby([\"label\", \"fold\"]).size().unstack(fill_value=0).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5092eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────── 셀 3 (재수정) ─────────────────────\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2, numpy as np\n",
    "\n",
    "# \"convnext_base\" 전용\n",
    "# MEAN, STD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "# \"convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384\" 전용\n",
    "MEAN, STD = [0.48145466, 0.4578275, 0.40821073], [0.26862954, 0.26130258, 0.27577711]\n",
    "\n",
    "IMG_MAX   = max(CFG[\"IMG_SIZES\"].values())           # 512\n",
    "\n",
    "# 1) Half-crop ----------------------------------------------------------\n",
    "def half_crop(img, **kw):\n",
    "    h, w, _ = img.shape\n",
    "    side = np.random.choice([\"top\", \"bottom\", \"left\", \"right\"])\n",
    "    if   side == \"top\":    img = img[:h//2]\n",
    "    elif side == \"bottom\": img = img[h//2:]\n",
    "    elif side == \"left\":   img = img[:, :w//2]\n",
    "    else:                  img = img[:,  w//2:]\n",
    "    return img\n",
    "half_crop_aug = A.Lambda(image=half_crop)\n",
    "\n",
    "# 2) 우측-상단 마스킹 ---------------------------------------------------\n",
    "def mask_rand_tr(img, frac=(0.10, 0.25), **kw):\n",
    "    h, w, _ = img.shape\n",
    "    ph, pw = int(h * np.random.uniform(*frac)), int(w * np.random.uniform(*frac))\n",
    "    img[0:ph, w-pw:w] = 0\n",
    "    return img\n",
    "mask_ur_aug = A.Lambda(image=mask_rand_tr)\n",
    "\n",
    "# 3) Letter-box --------------------------------------------------------\n",
    "def letterbox_block(sz):\n",
    "    return [\n",
    "        A.LongestMaxSize(max_size=sz, interpolation=cv2.INTER_CUBIC),\n",
    "        A.PadIfNeeded(min_height=sz, min_width=sz,\n",
    "                      border_mode=cv2.BORDER_CONSTANT, fill=0),\n",
    "    ]\n",
    "\n",
    "# 4) build_aug ---------------------------------------------------------\n",
    "def build_aug(sz: int, phase: str = \"train\"):\n",
    "    if phase == \"train\":\n",
    "        # return A.Compose([\n",
    "        #     # (a) 10 % 확률 스티커 마스킹\n",
    "        #     A.OneOf([mask_ur_aug, A.NoOp()], p=0.10),\n",
    "\n",
    "        #     # (b) half-crop 20 %  vs  RandomResizedCrop 80 %\n",
    "        #     A.OneOf([\n",
    "        #         A.Lambda(image=half_crop, p=1.0),                    # half-crop\n",
    "        #         A.RandomResizedCrop(size=(sz, sz),                   # ★ tuple!\n",
    "        #                             scale=(0.8, 1.0),\n",
    "        #                             ratio=(0.75, 1.333), p=1.0),\n",
    "        #     ], p=1.0),\n",
    "        #     # A.RandomResizedCrop(size=(sz, sz),                   # ★ tuple!\n",
    "        #     #         scale=(0.5, 1.0),\n",
    "        #     #         ratio=(0.75, 1.333), p=1.0),\n",
    "        #     # (c) Letter-box로 정확히 sz×sz\n",
    "        #     *letterbox_block(sz),\n",
    "\n",
    "        #     # (d) 약한 변형\n",
    "        #     A.HorizontalFlip(p=0.25),\n",
    "        #     A.Perspective(scale=(0.05, 0.1), p=0.20),\n",
    "        #     A.OneOf([\n",
    "        #         A.ColorJitter(0.4, 0.4, 0.4, 0.1, p=1.0),\n",
    "        #         A.Affine(translate_percent=(0.05, 0.05),\n",
    "        #                  scale=(0.9, 1.1), rotate=(-15, 15), p=1.0),\n",
    "        #     ], p=1.0),\n",
    "        #     A.ToGray(p=0.10),\n",
    "\n",
    "        #     # (e) CoarseDropout — letter-box 이후\n",
    "        #     A.CoarseDropout(\n",
    "        #         num_holes_range=(1, 2),\n",
    "        #         hole_height_range=(int(sz*0.10), int(sz*0.25)),\n",
    "        #         hole_width_range =(int(sz*0.10), int(sz*0.25)),\n",
    "        #         fill=0, p=0.50\n",
    "        #     ),\n",
    "\n",
    "        #     A.Normalize(MEAN, STD),\n",
    "        #     ToTensorV2(),\n",
    "        # ])\n",
    "\n",
    "        # 1. RandomResizedCrop 블록 정의\n",
    "        rrc = A.RandomResizedCrop(\n",
    "                size=(sz, sz),\n",
    "                scale=(0.5, 1.0),  # 원본의 30%까지 잘라내어 부분만 보는 훈련 강화\n",
    "                ratio=(0.75, 1.333),\n",
    "                p=1.0\n",
    "            )\n",
    "\n",
    "        # 2. Letterbox 블록 정의 (기존 val_tf와 동일)\n",
    "        letter = A.Compose([\n",
    "                *letterbox_block(sz) # LongestMaxSize + PadIfNeeded\n",
    "            ])\n",
    "\n",
    "        return A.Compose([\n",
    "            # (a) 10 % 확률 스티커 마스킹\n",
    "            A.OneOf([mask_ur_aug, A.NoOp()], p=0.10),\n",
    "\n",
    "            # ★★★ 50:50 확률로 두 리사이징 전략 중 하나를 선택 ★★★\n",
    "            A.OneOf([rrc, letter], p=1.0),\n",
    "\n",
    "            # 2. 기하학적 변환: 다양한 구도와 각도 대응\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # Perspective와 Affine을 낮은 확률로 함께 사용하여 복합적인 왜곡 생성\n",
    "            A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "            A.Affine(translate_percent=0.1, scale=(0.9, 1.1), rotate=(-15, 15), shear=(-10, 10), p=0.3),\n",
    "\n",
    "            # 3. 색상/조명/노이즈 변환: 까다로운 조명 조건 대응\n",
    "            A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05, p=0.8),\n",
    "            A.ToGray(p=0.15),\n",
    "            # 저조도 환경의 노이즈와 블러를 시뮬레이션\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(p=1.0),\n",
    "                A.ISONoise(p=1.0),\n",
    "            ], p=0.2),\n",
    "\n",
    "            # 4. 가려짐(Occlusion) 시뮬레이션\n",
    "            # A.Erasing(\n",
    "            #     p=0.3,\n",
    "            #     scale=(0.02, 0.25), # 이미지의 2% ~ 25% 영역을 무작위 노이즈로 지움\n",
    "            #     ratio=(0.3, 3.3)\n",
    "            # ),\n",
    "            # 5. 정규화\n",
    "            A.Normalize(MEAN, STD),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    # ----- val / test -----\n",
    "    return A.Compose([\n",
    "        *letterbox_block(sz),\n",
    "        A.Normalize(MEAN, STD),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "# warm-up(256) 초기화\n",
    "train_tf = build_aug(256, \"train\")\n",
    "val_tf   = build_aug(256, \"val\")\n",
    "print(\"✅ Albumentations pipeline ready (progressive-resize compatible)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────  셀 4  ────────────────────────────────\n",
    "import cv2, torch, numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "class HardPairSampler(Sampler):\n",
    "    def __init__(self, cls2idx, hard_pairs, batch_size, total_samples, prob=0.3):\n",
    "        self.cls2idx = cls2idx\n",
    "        self.hard_pairs = list(hard_pairs) if hard_pairs else []\n",
    "        self.batch_size = batch_size\n",
    "        self.total_samples = total_samples\n",
    "        self.prob = prob\n",
    "        \n",
    "        self.all_indices = list(range(total_samples))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 전체 데이터 길이에 맞춰 배치 개수 계산\n",
    "        num_batches = self.total_samples // self.batch_size\n",
    "        \n",
    "        for _ in range(num_batches):\n",
    "            # 30% 확률로 Hard-pair 배치 생성\n",
    "            if self.hard_pairs and random.random() < self.prob:\n",
    "                batch_indices = []\n",
    "                # 배치 크기/2 만큼의 hard pair를 샘플링\n",
    "                for _ in range(self.batch_size // 2):\n",
    "                    # hard_pairs에서 무작위로 클래스 쌍 선택\n",
    "                    anchor_cls, positive_cls = random.choice(self.hard_pairs)\n",
    "                    \n",
    "                    # 각 클래스에서 이미지 인덱스를 하나씩 샘플링\n",
    "                    # 샘플이 1개뿐인 경우를 대비한 예외 처리\n",
    "                    anchor_idx = random.choice(self.cls2idx.get(anchor_cls, [0]))\n",
    "                    positive_idx = random.choice(self.cls2idx.get(positive_cls, [0]))\n",
    "                    \n",
    "                    batch_indices.extend([anchor_idx, positive_idx])\n",
    "                yield batch_indices\n",
    "            else:\n",
    "                # 일반 무작위 샘플링\n",
    "                yield random.sample(self.all_indices, self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples // self.batch_size\n",
    "\n",
    "# ---------------- Dataset ----------------------------------------------\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, is_test: bool=False):\n",
    "        self.paths  = df[\"img_path\"].tolist()\n",
    "        self.labels = None if is_test else df[\"label\"].tolist()\n",
    "        self.tf = transform;  self.is_test = is_test\n",
    "\n",
    "        # 클래스별 인덱스 캐시 (anchor/positive 샘플링용)\n",
    "        cls2idx = defaultdict(list)\n",
    "        if not is_test:\n",
    "            for idx, lbl in enumerate(self.labels):\n",
    "                cls2idx[lbl].append(idx)\n",
    "        self.cls2idx = cls2idx\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # is_test 처리는 그대로\n",
    "        if self.is_test:\n",
    "            img = cv2.cvtColor(cv2.imread(self.paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "            if self.tf: img = self.tf(image=img)[\"image\"]\n",
    "            return img, self.paths[idx]\n",
    "        \n",
    "        # 항상 이미지 하나와 라벨 하나만 반환\n",
    "        img = cv2.cvtColor(cv2.imread(self.paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "        if self.tf: img = self.tf(image=img)[\"image\"]\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "# ---------------- CutMix / MixUp helper ---------------------------------\n",
    "def rand_bbox(W, H, lam):\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return int(bbx1), int(bby1), int(bbx2), int(bby2)\n",
    "\n",
    "def collate_cutmix(batch, alpha: float = 1.0, prob: float = 0.1):\n",
    "    imgs, labels = list(zip(*batch))\n",
    "    imgs, labels = torch.stack(imgs), torch.tensor(labels)\n",
    "    labels2 = labels\n",
    "    \n",
    "    if np.random.rand() < prob:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        rand_idx = torch.randperm(imgs.size(0))\n",
    "        imgs2, labels2 = imgs[rand_idx], labels[rand_idx]\n",
    "\n",
    "        _, H, W = imgs.shape[1:]\n",
    "        x1, y1, x2, y2 = rand_bbox(W, H, lam)   # ← tuple 언팩 OK\n",
    "        imgs[:, :, y1:y2, x1:x2] = imgs2[:, :, y1:y2, x1:x2]\n",
    "\n",
    "        lam = 1.0 - (x2 - x1) * (y2 - y1) / (W * H)\n",
    "    else:\n",
    "        lam, labels2 = 1.0, labels\n",
    "\n",
    "    return imgs, labels, labels2, lam\n",
    "\n",
    "def collate_mixup(batch, alpha=0.2):\n",
    "    imgs, labels = list(zip(*batch)); imgs = torch.stack(imgs); labels = torch.tensor(labels)\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_idx = torch.randperm(imgs.size(0))\n",
    "    imgs = lam*imgs + (1-lam)*imgs[rand_idx]\n",
    "    labels2 = labels[rand_idx]\n",
    "    return imgs, labels, labels2, lam\n",
    "\n",
    "def collate_plain(batch):\n",
    "    imgs, labels = list(zip(*batch))\n",
    "    return torch.stack(imgs), torch.tensor(labels)\n",
    "\n",
    "# ---------------- collate_fn dispatcher ---------------------------------\n",
    "def get_collate_fn(epoch):\n",
    "    if   epoch <= 15: return lambda b: collate_cutmix(b, alpha=1.0, prob=0.3)\n",
    "    elif epoch <= 20: return lambda b: collate_mixup(b, alpha=0.2)\n",
    "    else:             return collate_plain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────  셀 5  ────────────────────────────────\n",
    "def make_loaders(fold:int,\n",
    "                 df_full,\n",
    "                 epoch:int,\n",
    "                 train_tf,\n",
    "                 val_tf,\n",
    "                 batch_size:int = 32,\n",
    "                 num_workers:int = 10,\n",
    "                 hard_pairs: set | None = None):   # 🔸추가\n",
    "    \"\"\"\n",
    "    epoch : 현재 epoch 번호 (증강·Collate 스케줄용)\n",
    "    \"\"\"\n",
    "    train_df = df_full[df_full.fold != fold].reset_index(drop=True)\n",
    "    val_df   = df_full[df_full.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    train_set = CarDataset(train_df, transform=train_tf)\n",
    "    val_set   = CarDataset(val_df,   transform=val_tf)\n",
    "\n",
    "    # 1. HardPairSampler 인스턴스 생성\n",
    "    sampler = HardPairSampler(\n",
    "        cls2idx=train_set.cls2idx,\n",
    "        hard_pairs=hard_pairs,\n",
    "        batch_size=batch_size,\n",
    "        total_samples=len(train_set)\n",
    "    )\n",
    "\n",
    "    base_collate_fn = get_collate_fn(epoch)\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_sampler=sampler, # ★ shuffle 대신 batch_sampler 사용\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=base_collate_fn\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=collate_plain\n",
    "    )\n",
    "\n",
    "    # test_paths = sorted([os.path.join(TEST_DIR,f)\n",
    "    #                      for f in os.listdir(TEST_DIR) if f.lower().endswith(\".jpg\")])\n",
    "    # test_set = CarDataset(pd.DataFrame({\"img_path\":test_paths}),\n",
    "    #                       transform=val_tf, is_test=True)\n",
    "    # test.csv를 직접 읽어 순서를 보장해야 합니다.\n",
    "    test_df = pd.read_csv(os.path.join(ROOT, \"data\", \"test.csv\"))\n",
    "    # test.csv의 경로가 상대 경로일 수 있으므로 절대 경로로 변환\n",
    "    test_df['img_path'] = test_df['img_path'].apply(lambda p: os.path.join(ROOT, \"data\", p))\n",
    "    test_set = CarDataset(test_df, transform=val_tf, is_test=True)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=lambda b: (torch.stack([x[0] for x in b]),\n",
    "                              [x[1] for x in b])\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────  셀 6 (모델 정의) ────────────────────────────────\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, timm\n",
    "from einops import rearrange\n",
    "\n",
    "# --------------------------- GeM Pool -----------------------------------------\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p: float = 3.0, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.p   = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p),\n",
    "                            kernel_size=(x.size(-2), x.size(-1))\n",
    "                           ).pow(1.0/self.p).flatten(1)\n",
    "\n",
    "# -------------------- Sub-center ArcFace Head (k=3, s=30, m=0.25) -------------\n",
    "class ArcMarginProduct_subcenter(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features:  int,\n",
    "                 out_features: int,\n",
    "                 k: int   = 3,\n",
    "                 s: float = 30.0,   # ⬆ scale 30 \n",
    "                 m: float = 0.25):  # ⬆ margin 0.50 → 0.25\n",
    "        super().__init__()\n",
    "        self.out_features, self.k, self.s, self.m = out_features, k, s, m\n",
    "        self.weight = nn.Parameter(torch.randn(out_features * k, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x, label: torch.Tensor | None = None):\n",
    "        x_norm = F.normalize(x, dim=1)\n",
    "        w_norm = F.normalize(self.weight, dim=1)\n",
    "\n",
    "        cosine = F.linear(x_norm, w_norm)           # (B, out*k)\n",
    "        cosine = cosine.view(-1, self.out_features, self.k)\n",
    "        cos_max, _ = torch.max(cosine, dim=2)       # (B, out)\n",
    "\n",
    "        if label is None:               # inference (margin X)\n",
    "            return self.s * cos_max\n",
    "        # ---------- margin 추가 (학습) ----------\n",
    "        theta   = torch.acos(cos_max.clamp(-1+1e-7, 1-1e-7))\n",
    "        cos_m   = torch.cos(theta + self.m)\n",
    "        one_hot = F.one_hot(label, self.out_features).float().to(x.device)\n",
    "        logits  = self.s * (one_hot * cos_m + (1.0 - one_hot) * cos_max)\n",
    "        return logits\n",
    "\n",
    "# --------------------------- Backbone + Head -----------------------------------\n",
    "class CarNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes: int,\n",
    "                 k: int = 3,\n",
    "                 s: float = 30.0,\n",
    "                 m: float = 0.25,\n",
    "                 drop_path_rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            \"convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384\",\n",
    "            pretrained=True,\n",
    "            features_only=True, # ★ 중요: 여러 단계의 특징 맵을 리스트로 반환하도록 설정\n",
    "            drop_path_rate=drop_path_rate          # ⬆ DropPath 0.1\n",
    "        )\n",
    "\n",
    "        # 2. 백본의 마지막 두 단계의 출력 채널 수를 가져옴\n",
    "        feature_info = self.backbone.feature_info.channels()\n",
    "        # 예: convnext_base -> [128, 256, 512, 1024] -> 마지막 두 개는 512, 1024\n",
    "        in_dim1 = feature_info[-2] # 두 번째 마지막 특징 맵의 채널 수 (로컬 정보)\n",
    "        in_dim2 = feature_info[-1] # 마지막 특징 맵의 채널 수 (글로벌 정보)\n",
    "\n",
    "        # 3. 각 특징 맵에 적용할 별도의 GeM 풀링 레이어 2개 생성\n",
    "        self.pool1 = GeM(p=3)\n",
    "        self.pool2 = GeM(p=3)\n",
    "\n",
    "        # ★★★ 정규화 레이어 추가 ★★★\n",
    "        # 각 특징 벡터의 차원에 맞는 LayerNorm을 각각 생성합니다.\n",
    "        self.norm1 = nn.LayerNorm(in_dim1)\n",
    "        self.norm2 = nn.LayerNorm(in_dim2)\n",
    "\n",
    "        # 4. 두 특징 벡터를 연결할 것이므로, 헤드의 입력 차원은 두 차원의 합\n",
    "        head_in_dim = in_dim1 + in_dim2\n",
    "\n",
    "        self.head = ArcMarginProduct_subcenter(\n",
    "            in_features=head_in_dim, \n",
    "            out_features=n_classes, \n",
    "            k=k, s=s, m=m)\n",
    "\n",
    "    def forward(self, x, label: torch.Tensor | None = None, return_feat=False):\n",
    "        # 1. 백본에서 특징 맵 리스트를 받아옴\n",
    "        features = self.backbone(x) # [map1, map2, map3, map4]\n",
    "\n",
    "        # 2. 마지막 두 개의 특징 맵을 각각 풀링\n",
    "        feat1 = self.pool1(features[-2]) # 로컬 특징\n",
    "        feat2 = self.pool2(features[-1]) # 글로벌 특징\n",
    "\n",
    "        # ★★★ 각 특징 벡터를 정규화 ★★★\n",
    "        norm_feat1 = self.norm1(feat1)\n",
    "        norm_feat2 = self.norm2(feat2)\n",
    "\n",
    "        # 3. 정규화된 특징 벡터들을 연결합니다.\n",
    "        feat_combined = torch.cat([norm_feat1, norm_feat2], dim=1)\n",
    "\n",
    "        # 4. 연결된 특징으로 로짓 계산\n",
    "        logits = self.head(feat_combined, label)\n",
    "        return (logits, feat_combined) if return_feat else logits\n",
    "\n",
    "# --------------------------- 예시 인스턴스 -------------------------------------\n",
    "n_classes = len(class_names)         # 396\n",
    "model = CarNet(n_classes).to(device)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "model = torch.compile(model)         # PyTorch ≥ 2.0\n",
    "\n",
    "print(\"✅ Model initialized – ConvNeXt-B (DropPath 0.1) + GeM + Sub-center ArcFace \"\n",
    "      f\"(k=3, s=30, m=0.25)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a98457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────  셀 7 : 학습 세트업  ───────────────────────────────\n",
    "# 1) 모델은 셀 6에서 이미 생성되어 있음 (model)\n",
    "\n",
    "# 2) Loss (초기값만, epoch 루프에서 0.10→0.05로 갱신)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# 3) Optimizer ── Backbone lr = CFG[\"LR\"], Head lr = ×5\n",
    "def param_groups(model, base_lr, head_lr_mul=5):\n",
    "    back, head = [], []\n",
    "    for n,p in model.named_parameters():\n",
    "        (head if \"head\" in n else back).append(p)\n",
    "    return [{\"params\":back,  \"lr\":base_lr},\n",
    "            {\"params\":head,  \"lr\":base_lr*head_lr_mul}]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_groups(model, CFG[\"LR\"]),\n",
    "    lr=CFG[\"LR\"], weight_decay=1e-2\n",
    ")\n",
    "\n",
    "\n",
    "# 5) AMP & EMA\n",
    "scaler      = torch.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "ema_decay   = 0.997\n",
    "ema_weights = [p.clone().detach() for p in model.parameters()]\n",
    "\n",
    "print(\"✅ Optimizer ready – Scheduler will be created inside the Fold loop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69212539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ──────────────────────────────  셀 8  (본학습용 LR Finder / 돌린 후 주석 처리) ─────────────────────────────\n",
    "# # ──────────────────────────────  반드시 주석 처리!!!!!!!!!!!!!!!!!!!!!!!!! ─────────────────────────────\n",
    "\n",
    "# from torch_lr_finder import LRFinder           # pip install torch-lr-finder\n",
    "# tmp_loader = DataLoader(                       # 작은 서브셋(예: 2~3k 샘플)\n",
    "#     CarDataset(df.sample(3000, random_state=0).reset_index(drop=True),\n",
    "#                transform=train_tf),\n",
    "#     batch_size=CFG[\"BATCH\"], shuffle=True, num_workers=4)\n",
    "\n",
    "# lr_finder = LRFinder(model, optimizer, criterion, device=device)\n",
    "# lr_finder.range_test(tmp_loader,\n",
    "#                      start_lr=1e-5, end_lr=1e-2,\n",
    "#                      num_iter=1000)\n",
    "# lr_finder.plot()    # 그래프 확인\n",
    "# lr_finder.reset()   # 옵티마이저 상태 복구\n",
    "# # ▲▲▲ LR Finder 끝 ───────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────  셀 9  (W&B 로깅 통합) ─────────────────────────────\n",
    "import time, math, os, numpy as np, wandb, torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto       import tqdm\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "from timm.layers     import DropPath\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "\n",
    "# ╭─ W&B 기본 ─────────────────────────────────────────────────────────────────╮\n",
    "WANDB_PROJECT = \"hecto_car_version3_0613\"\n",
    "WANDB_RUNNAME = f\"convnextB_k5_bs\"\n",
    "TOP_K         = 300\n",
    "HEAD_MULT     = 5          # back-bone LR 1 ×, head LR 5 ×\n",
    "device        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# ╰────────────────────────────────────────────────────────────────────────────╯\n",
    "\n",
    "\n",
    "# ───────── DropPath helper ───────────────────────────────────────────────────\n",
    "def set_drop_path(model, p: float):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, DropPath):\n",
    "            m.drop_prob = p\n",
    "\n",
    "# ───────── EMA · 기타 ────────────────────────────────────────────────────────\n",
    "def update_ema(model, ema_w, d):\n",
    "    with torch.no_grad():\n",
    "        for p, e in zip(model.parameters(), ema_w):\n",
    "            e.mul_(d).add_(p.data, alpha=1 - d)\n",
    "\n",
    "def param_groups(model, lr, head_mult: int = HEAD_MULT):\n",
    "    back, head = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        (head if \"head\" in n else back).append(p)\n",
    "    return [{\"params\": back,  \"lr\": lr},\n",
    "            {\"params\": head,  \"lr\": lr * head_mult}]\n",
    "\n",
    "def topk_accuracy(logits, labels, topk=(1, 5)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        _, pred = logits.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "        return [correct[:k].reshape(-1).float().mean().item() for k in topk]\n",
    "\n",
    "def grad_global_norm(model):\n",
    "    total = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            total += p.grad.detach().float().pow(2).sum().item()\n",
    "    return total ** 0.5\n",
    "\n",
    "def build_scheduler(optimizer, warm_iters, main_iters, eta_min=0.0):\n",
    "    \"\"\"(Warm-up → Cosine) or 단일 Cosine 스케줄러 반환\"\"\"\n",
    "    if warm_iters == 0:\n",
    "        return CosineAnnealingLR(optimizer, T_max=main_iters, eta_min=eta_min)\n",
    "    warm  = LinearLR(optimizer,  start_factor=0.05, end_factor=1.0,\n",
    "                     total_iters=warm_iters)\n",
    "    cos   = CosineAnnealingLR(optimizer, T_max=main_iters, eta_min=eta_min)\n",
    "    return SequentialLR(optimizer, [warm, cos], milestones=[warm_iters])\n",
    "\n",
    "# ─────────────── train / val 루프 ────────────────────────────────────────────\n",
    "def train_one_epoch(model, loader, scaler, optim, scheduler, ema_w, epoch):\n",
    "    model.train()\n",
    "    run_loss = grad_acc = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"Ep{epoch:02d} ▸ train\", leave=False)\n",
    "\n",
    "    for i, batch in enumerate(pbar, 1):\n",
    "        if len(batch) == 4:\n",
    "            x, y1, y2, lam = batch\n",
    "        else:\n",
    "            x, y1 = batch;  y2, lam = y1, 1.0\n",
    "\n",
    "        x   = x.to(device, memory_format=torch.channels_last)\n",
    "        y1, y2 = y1.to(device), y2.to(device)\n",
    "\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(device==\"cuda\")):\n",
    "            if lam < 1.0:\n",
    "                logits1 = model(x, label=y1)\n",
    "                logits2 = model(x, label=y2)\n",
    "                loss = lam*criterion(logits1, y1) + (1-lam)*criterion(logits2, y2)\n",
    "            else:\n",
    "                logits = model(x, label=y1)\n",
    "                loss   = criterion(logits, y1)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optim)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        grad_acc += grad_global_norm(model)\n",
    "\n",
    "        scaler.step(optim);  scaler.update();  scheduler.step()\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        update_ema(model, ema_w, ema_decay)\n",
    "\n",
    "        run_loss += loss.item()\n",
    "        pbar.set_postfix(L=f\"{run_loss/i:.4f}\")\n",
    "\n",
    "    return run_loss/i, grad_acc/i\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, loader, epoch, hard_prev):\n",
    "    model.eval()\n",
    "    vloss, logL, lblL = [], [], []\n",
    "    with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\", enabled=(device==\"cuda\")):\n",
    "        for x, l in tqdm(loader, desc=f\"Ep{epoch:02d} ▸ val\", leave=False):\n",
    "            x, l = x.to(device, memory_format=torch.channels_last), l.to(device)\n",
    "            logits, _ = model(x, label=None, return_feat=True)\n",
    "            vloss.append(criterion(logits, l).item())\n",
    "            logL.append(logits.cpu()); lblL.append(l.cpu())\n",
    "\n",
    "    logitsT = torch.cat(logL);  labelsT = torch.cat(lblL)\n",
    "    probs   = logitsT.softmax(1).numpy()\n",
    "    val_ll  = log_loss(labelsT, probs, labels=list(range(n_classes)))\n",
    "    top1, top5 = topk_accuracy(logitsT, labelsT)\n",
    "    avg_maxP   = probs.max(1).mean()\n",
    "\n",
    "    # ── Hard-pair mining\n",
    "    cm = confusion_matrix(labelsT.numpy(), probs.argmax(1), labels=range(n_classes))\n",
    "    cm[np.diag_indices_from(cm)] = 0\n",
    "    flat = np.argpartition(cm.reshape(-1), -TOP_K)[-TOP_K:]\n",
    "    r, c = np.unravel_index(flat, cm.shape)\n",
    "    hard_new = {(int(a), int(b)) for a, b in zip(r, c) if cm[a, b] > 0}\n",
    "    new_cnt, retired_cnt = len(hard_new - hard_prev), len(hard_prev - hard_new)\n",
    "    conf_err = int(cm.sum())\n",
    "\n",
    "    return (np.mean(vloss), val_ll, top1, top5, probs, labelsT.numpy(),\n",
    "            hard_new, conf_err, avg_maxP, new_cnt, retired_cnt)\n",
    "\n",
    "# ───────── Fold-level 하이퍼파라미터 ───────────────────────────────────────────\n",
    "FT_LR_SCALE = 1.5\n",
    "SCALE_MAP   = {256:1.0, 384:1.0, 512:0.9, 640:0.5, 768:0.3}   # 해상도별 배수\n",
    "\n",
    "fold_best, all_logits, all_labels = [], [], []\n",
    "\n",
    "for fold in range(CFG[\"FOLDS\"]):\n",
    "    hard_pairs_global = set()\n",
    "    run = wandb.init(project=WANDB_PROJECT,\n",
    "                     name=f\"{WANDB_RUNNAME}_fold{fold}\",\n",
    "                     config={**CFG, \"fold\": fold}, reinit=True)\n",
    "\n",
    "    # ── 모델 & Optimizer (처음은 256 px 기준)\n",
    "    model = CarNet(len(class_names), k=3, s=30.0, m=0.25)\\\n",
    "            .to(device).to(memory_format=torch.channels_last)\n",
    "\n",
    "    base_lr_init = CFG[\"LR\"] * SCALE_MAP[256]\n",
    "    optimizer = torch.optim.AdamW(param_groups(model, base_lr_init, HEAD_MULT),\n",
    "                                  lr=base_lr_init,  weight_decay=1e-2)\n",
    "\n",
    "    scaler      = torch.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "    ema_decay   = 0.997\n",
    "    ema_weights = [p.detach().clone() for p in model.parameters()]\n",
    "    best_ll, last_ll = math.inf, None\n",
    "\n",
    "    finetune_start_epoch = CFG[\"EPOCH\"] - CFG[\"FT_EPOCHS\"]\n",
    "\n",
    "    # ── 첫 DataLoader · Scheduler 생성 (256 px)\n",
    "    img_sz   = 256\n",
    "    batch_sz = CFG[\"BATCH_SIZES\"][img_sz]\n",
    "\n",
    "    train_tf = build_aug(img_sz, \"train\")\n",
    "    val_tf   = build_aug(img_sz, \"val\")\n",
    "    train_loader, val_loader, _ = make_loaders(\n",
    "        fold, df_full=df, epoch=0,\n",
    "        train_tf=train_tf, val_tf=val_tf,\n",
    "        batch_size=batch_sz, num_workers=10, hard_pairs=hard_pairs_global)\n",
    "\n",
    "    steps_ep  = len(train_loader)\n",
    "    warm_it   = 3 * steps_ep\n",
    "    main_it   = max(1, (CFG[\"IMG_SIZES\"][6] - 0) * steps_ep - warm_it)  # 256 → 384 구간\n",
    "    scheduler = build_scheduler(optimizer, warm_it, main_it, eta_min=base_lr_init*0.1)\n",
    "\n",
    "    # ── Epoch Loop ────────────────────────────────────────────────────────────\n",
    "    for ep in range(CFG[\"EPOCH\"]):\n",
    "        # 상태 전환(해상도 변경 / Fine-tune 진입) 판정\n",
    "        is_resize_epoch        = ep in CFG[\"IMG_SIZES\"]\n",
    "        is_first_finetune_ep   = (ep == finetune_start_epoch)\n",
    "\n",
    "        if is_resize_epoch or is_first_finetune_ep:\n",
    "            if is_first_finetune_ep:               # Fine-tune(768 px)\n",
    "                img_sz   = CFG[\"FINAL_IMG_SIZE\"]\n",
    "                batch_sz = CFG[\"BATCH_SIZES\"][img_sz]\n",
    "                base_lr  = CFG[\"LR\"] * SCALE_MAP[768] * FT_LR_SCALE\n",
    "                print(f\"✨ Epoch {ep}: Entering Fine-tune at {img_sz}px\")\n",
    "            else:                                   # Progressive-resize\n",
    "                img_sz   = CFG[\"IMG_SIZES\"][ep]\n",
    "                batch_sz = CFG[\"BATCH_SIZES\"][img_sz]\n",
    "                base_lr  = CFG[\"LR\"] * SCALE_MAP.get(img_sz, 0.3)\n",
    "                print(f\"✨ Epoch {ep}: Resize → {img_sz}px | Base LR {base_lr:.2e}\")\n",
    "\n",
    "            # Optimizer LR 갱신\n",
    "            for i, pg in enumerate(optimizer.param_groups):\n",
    "                pg[\"lr\"] = base_lr if i == 0 else base_lr * HEAD_MULT\n",
    "                pg[\"initial_lr\"] = pg[\"lr\"]\n",
    "\n",
    "            # DataLoader 재생성\n",
    "            train_tf = build_aug(img_sz, \"train\")\n",
    "            val_tf   = build_aug(img_sz, \"val\")\n",
    "            train_loader, val_loader, _ = make_loaders(\n",
    "                fold, df_full=df, epoch=ep,\n",
    "                train_tf=train_tf, val_tf=val_tf,\n",
    "                batch_size=batch_sz, num_workers=10,\n",
    "                hard_pairs=hard_pairs_global)\n",
    "\n",
    "            steps_ep  = len(train_loader)\n",
    "            if is_first_finetune_ep:\n",
    "                # EMA 재초기화\n",
    "                for e, p in zip(ema_weights, model.parameters()):\n",
    "                    e.copy_(p.detach())\n",
    "                warm_it = 0\n",
    "                main_it = (CFG[\"EPOCH\"] - ep) * steps_ep\n",
    "                eta_min = 0.0\n",
    "            else:\n",
    "                # 현 스테이지 잔여 에폭 계산\n",
    "                next_switch_ep = min(\n",
    "                    [k for k in list(CFG[\"IMG_SIZES\"].keys())+[finetune_start_epoch] if k > ep] or [CFG[\"EPOCH\"]])\n",
    "                stage_epochs = next_switch_ep - ep\n",
    "                warm_it = 3 * steps_ep\n",
    "                main_it = max(1, stage_epochs*steps_ep - warm_it)\n",
    "                eta_min = base_lr * 0.1\n",
    "\n",
    "            scheduler = build_scheduler(optimizer, warm_it, main_it, eta_min)\n",
    "\n",
    "        # Loss 함수(LS 가변)\n",
    "        if ep >= finetune_start_epoch:\n",
    "            model.head.m = 0.0\n",
    "            criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "        else:\n",
    "            criterion = torch.nn.CrossEntropyLoss(label_smoothing=(0.05 if ep <= 15 else 0.0))\n",
    "\n",
    "        # DropPath\n",
    "        set_drop_path(model.backbone, 0.1 * ep / CFG[\"EPOCH\"])\n",
    "\n",
    "        # Train / Val\n",
    "        tr_loss, tr_gn = train_one_epoch(model, train_loader, scaler,\n",
    "                                         optimizer, scheduler, ema_weights, ep)\n",
    "\n",
    "        vl_loss, vl_ll, top1, top5, vl_probs, vl_lbls,\\\n",
    "        hard_pairs_global, conf_err, avg_maxP, hp_new, hp_ret = \\\n",
    "            validate_one_epoch(model, val_loader, ep, hard_pairs_global)\n",
    "\n",
    "        logdiff = 0.0 if last_ll is None else (vl_ll - last_ll)\n",
    "        last_ll = vl_ll\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": ep, \"train_loss\": tr_loss, \"val_loss\": vl_loss,\n",
    "            \"logloss\": vl_ll, \"logloss_diff\": logdiff,\n",
    "            \"loss_gap\": abs(tr_loss-vl_loss),\n",
    "            \"top1\": top1, \"top5\": top5,\n",
    "            \"conf_err\": conf_err, \"avg_maxP_val\": avg_maxP,\n",
    "            \"hard_pairs\": len(hard_pairs_global),\n",
    "            \"hard_pairs/new\": hp_new, \"hard_pairs/retired\": hp_ret,\n",
    "            \"grad_norm\": tr_gn,\n",
    "            \"lr\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f\"[Ep{ep:02d}] Train {tr_loss:.4f} | Val {vl_loss:.4f} | \"\n",
    "              f\"LL {vl_ll:.5f} Δ{logdiff:+.5f} | Top1 {top1*100:.2f}% | \"\n",
    "              f\"HP {len(hard_pairs_global)}(+{hp_new}/-{hp_ret}) | \"\n",
    "              f\"ConfErr {conf_err} | LR {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        if vl_ll < best_ll:\n",
    "            best_ll = vl_ll\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"ema\"  : [w.cpu() for w in ema_weights]},\n",
    "                f\"{ROOT}/best_model_fold{fold}.pth\")\n",
    "            wandb.save(f\"{ROOT}/best_model_fold{fold}.pth\", base_path=ROOT)\n",
    "\n",
    "    fold_best.append(best_ll)\n",
    "    all_logits.append(vl_probs);  all_labels.append(vl_lbls)\n",
    "    run.finish()\n",
    "    print(f\"🏁 Fold {fold} best LL {best_ll:.4f}\")\n",
    "\n",
    "# ───── OOF 저장 ───────────────────────────────────────────────────────────────\n",
    "ROOT = Path(ROOT)\n",
    "np.save(ROOT / \"oof_logits.npy\",  np.concatenate(all_logits).astype(np.float32))\n",
    "np.save(ROOT / \"oof_labels.npy\", np.concatenate(all_labels).astype(np.int32))\n",
    "print(\"🔚 CV mean LogLoss :\", f\"{np.mean(fold_best):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0536d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────  Cell 10-prep : train ↓ embeds  ─────────────────\n",
    "import torch, numpy as np, os\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT  = Path(ROOT)\n",
    "BATCH = 96\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_cls  = len(class_names)\n",
    "\n",
    "# 0) 헬퍼 ────────────────────────────────────────────────────────────\n",
    "def backbone_forward_feat(bk, x):\n",
    "    \"\"\"\n",
    "    timm backbone 이\n",
    "      • 일반 모델        → forward_features(x)  반환 (B,C,H,W)\n",
    "      • FeatureListNet   → bk(x)[-1]           반환 (B,C,H,W)\n",
    "    로 가변적이므로, 공통 인터페이스로 묶어 준다.\n",
    "    \"\"\"\n",
    "    if hasattr(bk, \"forward_features\"):\n",
    "        feat = bk.forward_features(x)\n",
    "    else:                               # FeatureListNet\n",
    "        out = bk(x)                     # list[Tensor] or tuple\n",
    "        feat = out[-1]                  # 마지막 stage\n",
    "    return feat                         # (B,C,H,W)\n",
    "\n",
    "# util.py ------------------------------------------\n",
    "def extract_feat(model: CarNet, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    학습 시 head 입력과 동일한 (concat·norm 포함) feature 반환.\n",
    "    \"\"\"\n",
    "    _, feat = model(x, label=None, return_feat=True)\n",
    "    return feat          # (B, C1+C2)\n",
    "\n",
    "\n",
    "# 1) Dataset (증강 X, val_tf 로 충분)\n",
    "train_set = CarDataset(df, transform=val_tf)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=BATCH, shuffle=False,\n",
    "    num_workers=8, pin_memory=True,\n",
    "    collate_fn=lambda b: torch.stack([t[0] for t in b]))\n",
    "\n",
    "# 2) backbone (fold0 모델 == feature space 통일)\n",
    "ckpt  = torch.load(ROOT / \"best_model_fold0.pth\", map_location=device)\n",
    "state = {k.replace(\"_orig_mod.\",\"\"): v for k,v in ckpt[\"model\"].items()}\n",
    "\n",
    "net = CarNet(n_cls, k=3).to(device).eval().to(memory_format=torch.channels_last)\n",
    "net.load_state_dict(state, strict=True)\n",
    "\n",
    "embeds = []\n",
    "with torch.no_grad(), torch.amp.autocast(device_type=device):\n",
    "    for x in tqdm(train_loader, desc=\"⏳ extract train emb\"):\n",
    "        x = x.to(device, memory_format=torch.channels_last)\n",
    "\n",
    "        # # ── 변경된 부분 ───────────────────────────────────────────────\n",
    "        # f = backbone_forward_feat(net.backbone, x)   # (B,C,H,W)\n",
    "        # f = net.pool(f).flatten(1)                  # (B, C)\n",
    "        # # embed BN 등이 있으면:  f = net.bn(f)\n",
    "\n",
    "        # ★★★ CarNet의 forward를 직접 호출하여 융합된 특징(feat)을 가져옴 ★★★\n",
    "        f = extract_feat(net, x)        # ← 단일 호출\n",
    "\n",
    "        embeds.append(f.cpu().numpy())\n",
    "\n",
    "embeds = np.vstack(embeds).astype(\"float32\")          # (N, dim)\n",
    "labels  = df[\"label\"].to_numpy().astype(\"int32\")\n",
    "\n",
    "np.save(ROOT / \"train_embeds.npy\", embeds)\n",
    "np.save(ROOT / \"train_labels.npy\", labels)\n",
    "print(\"✅ saved train_embeds.npy :\", embeds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────  셀 10  (k = 20, 30 추가) ───────────────────────────────\n",
    "#  • 이미 구축된 FAISS 인덱스 / 임베딩 재사용\n",
    "#  • k ∈ {20, 30, 50} 각각에 대해\n",
    "#      knn_prob_train_k{k}.npy\n",
    "#      knn_majority_ratio_k{k}.npy\n",
    "#    가 없으면 계산·저장, 있으면 건너뜀\n",
    "# ─────────────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "from pathlib import Path\n",
    "# ------------------------------------------------------------------\n",
    "ROOT = Path(ROOT)          # ← 문자열이면 Path 로, 이미 Path 면 그대로\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import faiss, torch, os, numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --------------- 전 단계 산출물 불러오기 -------------------------------------------------\n",
    "train_emb = np.load(f\"{ROOT}/train_embeds.npy\").astype(\"float32\")   # (N,dim)\n",
    "train_lbl = np.load(f\"{ROOT}/train_labels.npy\")                     # (N,)\n",
    "faiss.normalize_L2(train_emb)                                       # Cosine\n",
    "\n",
    "index_path = f\"{ROOT}/faiss_ip.index\"\n",
    "index = faiss.read_index(index_path) if os.path.exists(index_path) \\\n",
    "        else faiss.IndexFlatIP(train_emb.shape[1])\n",
    "if index.ntotal == 0:                        # 처음 실행 시만 add\n",
    "    index.add(train_emb)\n",
    "    faiss.write_index(index, index_path)\n",
    "print(f\"🔧 FAISS index ready  • vectors = {index.ntotal}\")\n",
    "\n",
    "# 이하 동일\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# ───────── k-NN 확률 산출 (self 제거) ──────────────────────────\n",
    "for K in [20, 30, 50]:\n",
    "    prob_file  = ROOT / f\"knn_prob_train_k{K}.npy\"\n",
    "    ratio_file = ROOT / f\"knn_majority_ratio_k{K}.npy\"\n",
    "\n",
    "    if prob_file.exists() and ratio_file.exists():\n",
    "        print(f\"✅ k={K} already exists – skipped\")\n",
    "        continue\n",
    "\n",
    "    print(f\"⇢ computing k-NN  (k={K}) …\")\n",
    "\n",
    "    D, I = index.search(train_emb, K + 1)   # self 포함 K+1\n",
    "    I = I[:, 1:]                            # self drop\n",
    "\n",
    "    knn_prob  = np.zeros((len(train_lbl), n_classes), dtype=np.float32)\n",
    "    for n, nbr in enumerate(I):\n",
    "        cls, cnt         = np.unique(train_lbl[nbr], return_counts=True)\n",
    "        knn_prob[n, cls] = cnt / K\n",
    "\n",
    "    maj_ratio = knn_prob.max(1)\n",
    "\n",
    "    np.save(prob_file,  knn_prob)\n",
    "    np.save(ratio_file, maj_ratio)\n",
    "    print(f\"  • saved {prob_file.name} | majority_ratio mean {maj_ratio.mean():.4f}\")\n",
    "\n",
    "print(\"\\n🏁  k-NN probability files regenerated without self-neighbor.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0deeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────  셀 12 : OOF  ‖  flip-TTA + Global-T ────────────────\n",
    "import os, numpy as np, pandas as pd, torch, optuna, joblib, kornia\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import log_loss\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT       = Path(ROOT)\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "FOLDS      = CFG[\"FOLDS\"]\n",
    "IMG_SIZE = CFG[\"FINAL_IMG_SIZE\"]\n",
    "N_CLASSES  = len(class_names)\n",
    "\n",
    "val_tf = build_aug(IMG_SIZE, phase=\"val\")          # = train val transform\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class CarDatasetOOF(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        img = Image.open(row.img_path).convert(\"RGB\")\n",
    "        img = val_tf(image=np.array(img))[\"image\"]\n",
    "        # row.name 대신, 'index' 열에 저장된 원래 인덱스 값을 반환\n",
    "        return img, row.label, row['index']            # row.name = 원래 인덱스\n",
    "\n",
    "def collate(batch):\n",
    "    return (torch.stack([b[0] for b in batch]),\n",
    "            torch.tensor([b[1] for b in batch]),\n",
    "            torch.tensor([b[2] for b in batch]))\n",
    "\n",
    "# ---------- OOF logits (flip-TTA, EMA X) ----------\n",
    "df_full    = df\n",
    "oof_logits = np.empty((len(df_full), N_CLASSES), np.float32)\n",
    "oof_labels = df_full.label.to_numpy().astype(np.int32)\n",
    "\n",
    "for f in range(FOLDS):\n",
    "    print(f\"🔎  OOF – fold {f}\")\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        CarDatasetOOF(df_full[df_full.fold == f].reset_index()), BATCH, False,\n",
    "        num_workers=10, pin_memory=True, collate_fn=collate)\n",
    "\n",
    "    ckpt  = torch.load(ROOT/f\"best_model_fold{f}.pth\", map_location=DEVICE)\n",
    "    state = {k.replace(\"_orig_mod.\",\"\"):v for k,v in ckpt[\"model\"].items()}\n",
    "    model = CarNet(N_CLASSES, k=3, s=30.0, m=0.25)\\\n",
    "            .to(DEVICE).to(memory_format=torch.channels_last).eval()\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    # EMA 가중치 및 버퍼 덮어쓰기\n",
    "    for p_ema, p in zip(ckpt[\"ema\"], model.parameters()):\n",
    "        p.data.copy_(p_ema.to(DEVICE))\n",
    "\n",
    "    if \"ema_buf\" in ckpt and len(ckpt[\"ema_buf\"]) == len(list(model.buffers())):\n",
    "        for b_ema, b in zip(ckpt[\"ema_buf\"], model.buffers()):\n",
    "            b.data.copy_(b_ema.to(DEVICE))\n",
    "\n",
    "    with torch.no_grad(), torch.amp.autocast(device_type=DEVICE, enabled=True):\n",
    "        for x, _, idx in tqdm(loader, leave=False):\n",
    "            x = x.to(DEVICE, memory_format=torch.channels_last)\n",
    "            log1 = model(x)\n",
    "            log2 = model(torch.flip(x, dims=[3]))      # h-flip\n",
    "            oof_logits[idx.numpy()] = ((log1 + log2) / 2).cpu().numpy()\n",
    "    del model; torch.cuda.empty_cache()\n",
    "\n",
    "np.save(ROOT/\"oof_logits_raw.npy\", oof_logits.astype(np.float32))\n",
    "np.save(ROOT/\"oof_labels.npy\",     oof_labels)\n",
    "\n",
    "# ---------- Global-T 단일 최적화 ----------\n",
    "def obj_global(trial):\n",
    "    T = trial.suggest_float(\"T\", 0.2, 4.0, log=True)\n",
    "    prob = torch.softmax(torch.tensor(oof_logits)/T, 1).numpy()\n",
    "    return log_loss(oof_labels, prob, labels=np.arange(N_CLASSES))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(obj_global, n_trials=200, show_progress_bar=False)\n",
    "T_global = study.best_params[\"T\"]; LL_global = study.best_value\n",
    "print(f\"🌡️ Global T = {T_global:.4f} | OOF LL = {LL_global:.6f}\")\n",
    "\n",
    "# ---------- 확률 & T 저장 ----------\n",
    "np.save(ROOT/\"best_Ts.npy\", np.array([T_global], np.float32))   # 길이 1\n",
    "prob_oof = torch.softmax(torch.tensor(oof_logits)/T_global,1)\\\n",
    "                 .numpy().astype(np.float32)\n",
    "np.save(ROOT/\"oof_logits_tta.npy\", prob_oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────  셀 13 : Test  ‖ flip-TTA + Global-T ────────────────\n",
    "import torch, numpy as np, os, pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ROOT     = Path(ROOT)\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "N_FOLDS  = CFG[\"FOLDS\"];  N_CLASS = len(class_names)\n",
    "BATCH = 32\n",
    "val_tf = build_aug(IMG_SIZE, phase=\"val\")\n",
    "\n",
    "# test_paths = sorted([os.path.join(TEST_DIR,f)\n",
    "#                      for f in os.listdir(TEST_DIR) if f.lower().endswith(\".jpg\")])\n",
    "# test_set = CarDataset(pd.DataFrame({\"img_path\":test_paths}),\n",
    "#                       transform=val_tf, is_test=True)\n",
    "\n",
    "# test.csv를 직접 읽어 제출 순서를 정확히 맞춰야 합니다.\n",
    "test_df = pd.read_csv(os.path.join(ROOT, \"data\", \"test.csv\"))\n",
    "# test.csv의 경로가 상대 경로일 수 있으므로 절대 경로로 변환\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda p: os.path.join(ROOT, \"data\", p))\n",
    "\n",
    "test_set = CarDataset(test_df, transform=val_tf, is_test=True)\n",
    "\n",
    "loader = DataLoader(test_set, BATCH, False, num_workers=10, pin_memory=True,\n",
    "                    collate_fn=lambda b: torch.stack([x[0] for x in b]))\n",
    "\n",
    "T_global = float(np.load(ROOT/\"best_Ts.npy\"))        # 0-D 또는 길이 1\n",
    "\n",
    "probs_fold = np.zeros((N_FOLDS, len(test_set), N_CLASS), np.float32)\n",
    "\n",
    "for f in range(N_FOLDS):\n",
    "    print(f\"🔸 Test – fold {f}\")\n",
    "    ckpt  = torch.load(ROOT/f\"best_model_fold{f}.pth\", map_location=DEVICE)\n",
    "    state = {k.replace(\"_orig_mod.\",\"\"):v for k,v in ckpt[\"model\"].items()}\n",
    "    model = CarNet(N_CLASS, k=3, s=30.0, m=0.25)\\\n",
    "            .to(DEVICE).to(memory_format=torch.channels_last).eval()\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    # EMA 가중치 및 버퍼 덮어쓰기\n",
    "    for p_ema, p in zip(ckpt[\"ema\"], model.parameters()):\n",
    "        p.data.copy_(p_ema.to(DEVICE))\n",
    "\n",
    "    if \"ema_buf\" in ckpt and len(ckpt[\"ema_buf\"]) == len(list(model.buffers())):\n",
    "        for b_ema, b in zip(ckpt[\"ema_buf\"], model.buffers()):\n",
    "            b.data.copy_(b_ema.to(DEVICE))\n",
    "\n",
    "    out = np.empty((len(test_set), N_CLASS), np.float32); ofs = 0\n",
    "    with torch.no_grad(), torch.amp.autocast(device_type=DEVICE, enabled=True):\n",
    "        for x in tqdm(loader, leave=False):\n",
    "            x = x.to(DEVICE, memory_format=torch.channels_last)\n",
    "            log1 = model(x)\n",
    "            log2 = model(torch.flip(x, [3]))\n",
    "            logits = (log1 + log2) / 2\n",
    "            prob   = torch.softmax(logits / T_global, 1)\n",
    "            bsz = len(x); out[ofs:ofs+bsz] = prob.cpu().numpy(); ofs += bsz\n",
    "    probs_fold[f] = out; del model; torch.cuda.empty_cache()\n",
    "\n",
    "prob_test = probs_fold.mean(0).astype(np.float32)\n",
    "np.save(ROOT/\"test_logits.npy\",  prob_test)\n",
    "np.save(ROOT/\"test_probs_f.npy\", probs_fold)\n",
    "print(\"✅ test_logits.npy 저장 :\", prob_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c00eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────  셀 14 : Test k-NN (k = 20·30·50 동시) ─────────────────────\n",
    "import torch, numpy as np, os, pandas as pd, faiss\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader          # ★ 추가\n",
    "\n",
    "# ── 파라미터 ───────────────────────────────────────────────────────────────────\n",
    "K_LIST      = [20, 30, 50]                    # 탐색할 k\n",
    "EMB_BATCH   = 96\n",
    "INDEX_PATH  = f\"{ROOT}/faiss_ip.index\"\n",
    "LABEL_PATH  = f\"{ROOT}/train_labels.npy\"\n",
    "\n",
    "# ── 헬퍼: timm FeatureListNet 호환 ────────────────────────────────────────────\n",
    "def backbone_forward_feat(bk, x):\n",
    "    \"\"\"\n",
    "    • 일반 timm 모델    → bk.forward_features(x)\n",
    "    • FeatureListNet    → bk(x)[-1]\n",
    "    둘 다 (B,C,H,W) 텐서를 반환.\n",
    "    \"\"\"\n",
    "    return bk.forward_features(x) if hasattr(bk, \"forward_features\") else bk(x)[-1]\n",
    "\n",
    "# ── 1. Index & train labels 로드 ───────────────────────────────────────────────\n",
    "assert os.path.exists(INDEX_PATH), \"train 임베딩 index 가 없습니다.\"\n",
    "index        = faiss.read_index(INDEX_PATH)          # IP + L2-normalized\n",
    "train_labels = np.load(LABEL_PATH)                   # (N_train,)\n",
    "n_train      = index.ntotal\n",
    "print(f\"🔧  FAISS index ready  • vectors = {n_train}\")\n",
    "\n",
    "# ── 2. 테스트 DataLoader  (셀13과 동일) ────────────────────────────────────────\n",
    "# test_paths = sorted([os.path.join(TEST_DIR, f)\n",
    "#                      for f in os.listdir(TEST_DIR) if f.lower().endswith(\".jpg\")])\n",
    "# test_df  = pd.DataFrame({\"img_path\": test_paths})\n",
    "# test_set = CarDataset(test_df, transform=val_tf, is_test=True)\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(ROOT, \"data\", \"test.csv\"))\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda p: os.path.join(ROOT, \"data\", p))\n",
    "test_set = CarDataset(test_df, transform=val_tf, is_test=True)\n",
    "\n",
    "def collate(batch):                  # (img,) 리스트 → Tensor\n",
    "    return torch.stack([b[0] for b in batch], 0)\n",
    "\n",
    "loader = DataLoader(test_set, batch_size=EMB_BATCH, shuffle=False,\n",
    "                    num_workers=8, pin_memory=True, collate_fn=collate)\n",
    "\n",
    "n_test   = len(test_set)\n",
    "n_class  = len(class_names)\n",
    "\n",
    "# ── 3. Backbone 로드 (fold0 모델) & 테스트 임베딩 추출 (1회) ──────────────────\n",
    "ckpt  = torch.load(f\"{ROOT}/best_model_fold0.pth\", map_location=device)\n",
    "state = {k.replace(\"_orig_mod.\", \"\"): v for k, v in ckpt[\"model\"].items()}\n",
    "\n",
    "embed_net = CarNet(n_class, k=3).to(device)\n",
    "embed_net.load_state_dict(state, strict=True)\n",
    "embed_net = embed_net.to(memory_format=torch.channels_last).eval()\n",
    "\n",
    "emb_test = []\n",
    "with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\" if device == \"cuda\" else \"cpu\"):\n",
    "    for x in tqdm(loader, desc=\"⇢ extract test emb\"):\n",
    "        x = x.to(device, memory_format=torch.channels_last)\n",
    "\n",
    "        # # ★ 변경: FeatureListNet 호환\n",
    "        # f = backbone_forward_feat(embed_net.backbone, x)   # (B,C,H,W)\n",
    "        # feat = embed_net.pool(f)                           # (B,C)\n",
    "        f = extract_feat(embed_net, x)\n",
    "        emb_test.append(f.cpu().numpy())\n",
    "\n",
    "emb_test = np.vstack(emb_test).astype(\"float32\")\n",
    "faiss.normalize_L2(emb_test)                            # Cosine 기반\n",
    "\n",
    "# ── 4. k-별 검색 & 확률 저장 ───────────────────────────────────────────────────\n",
    "for K in K_LIST:\n",
    "    out_file = f\"{ROOT}/knn_prob_test_k{K}.npy\"\n",
    "    if os.path.exists(out_file):\n",
    "        print(f\"⏩  {out_file} already exists – skip\")\n",
    "        continue\n",
    "\n",
    "    print(f\"⇢ computing k-NN  (k={K}) …\")\n",
    "    D, I = index.search(emb_test, K)                    # 최근접 K 인덱스\n",
    "\n",
    "    knn_prob = np.zeros((n_test, n_class), dtype=np.float32)\n",
    "    for n, nbr in enumerate(I):\n",
    "        cls, cnt = np.unique(train_labels[nbr], return_counts=True)\n",
    "        knn_prob[n, cls] = cnt / K\n",
    "\n",
    "    np.save(out_file, knn_prob)\n",
    "    maj_ratio = knn_prob.max(1).mean()\n",
    "    print(f\"  • saved {os.path.basename(out_file)}  | majority_ratio mean {maj_ratio:.4f}\")\n",
    "\n",
    "print(\"🏁 k-NN probability files ready for k =\", \", \".join(map(str, K_LIST)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeef194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────  Cell 15 : 최종 확률 산출 ─────────────────────\n",
    "\"\"\"\n",
    "● 이 셀은 모델 폴더 안에서 단독으로 실행\n",
    "   (ROOT = 현재 모델 디렉터리)  \n",
    "● 결과물: prob_test_blend.npy  ← 다른 모델과 앙상블 단계에서 사용\n",
    "\"\"\"\n",
    "import numpy as np, pandas as pd, os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "ROOT     = Path(os.getenv(\"ROOT\", \".\"))      # 모델 전용 디렉터리\n",
    "USE_KNN  = True\n",
    "\n",
    "# ── 1. 필수 파일 로드 ───────────────────────────────────────────────\n",
    "prob_oof   = np.load(ROOT / \"oof_logits_tta.npy\")      # (N_train,C)\n",
    "labels_oof = np.load(ROOT / \"oof_labels.npy\").astype(int)\n",
    "prob_test  = np.load(ROOT / \"test_logits.npy\")         # (N_test ,C)\n",
    "\n",
    "# class 이름을 sample_submission 로부터 확보\n",
    "sample_sub = next(ROOT.rglob(\"sample_submission.csv\"))\n",
    "class_names = pd.read_csv(sample_sub, nrows=0).columns[1:].tolist()\n",
    "C = len(class_names)\n",
    "\n",
    "# ── 2. pure-model OOF LL 확인 ───────────────────────────────────────\n",
    "oof_ll = log_loss(labels_oof, prob_oof, labels=np.arange(C))\n",
    "print(f\"🔎  OOF LogLoss (pure model) = {oof_ll:.6f}\")\n",
    "\n",
    "# ── 3. k-NN 블렌드 (옵션) ───────────────────────────────────────────\n",
    "prob_out = prob_test.copy()\n",
    "if USE_KNN:\n",
    "    k_list    = [15]\n",
    "    beta_grid = np.append(np.linspace(0.60, 0.95, 15), 1.00)\n",
    "    best_k = None; best_b = 1.0; best_ll = 1e9\n",
    "\n",
    "    print(\"\\n🔎  Grid-search β for k-NN blend\")\n",
    "    for k in k_list:\n",
    "        knn_oof = np.load(ROOT / f\"knn_prob_train_k{k}.npy\")\n",
    "        for b in beta_grid:\n",
    "            mix = b*prob_oof + (1-b)*knn_oof\n",
    "            mix /= mix.sum(1, keepdims=True)\n",
    "            ll  = log_loss(labels_oof, mix, labels=np.arange(C))\n",
    "            if ll < best_ll:\n",
    "                best_ll, best_b, best_k = ll, b, k\n",
    "\n",
    "    if best_k is not None and best_b < 1.0:\n",
    "        print(f\"✅  best k={best_k}  β={best_b:.2f}  OOF LL={best_ll:.6f}\")\n",
    "        knn_test = np.load(ROOT / f\"knn_prob_test_k{best_k}.npy\")\n",
    "        prob_out = best_b*prob_test + (1-best_b)*knn_test\n",
    "        prob_out /= prob_out.sum(1, keepdims=True)\n",
    "\n",
    "# ── 4. 최종 test 확률 저장 ──────────────────────────────────────────\n",
    "np.save(ROOT / \"prob_test_blend.npy\", prob_out.astype(np.float32))\n",
    "print(\"💾  prob_test_blend.npy saved :\", prob_out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369387e",
   "metadata": {},
   "source": [
    "**5fold x 2 모델 앙상블**\n",
    "\n",
    "셀15까지 돌린 후 모든 결과물을 아래와 비슷한 방식으로 폴더에 모두 옮긴 후 셀16 실행\n",
    "\n",
    "/work/\n",
    " ├─ model_A/          (ex. convnext_base)\n",
    " │   ├─ best_model_fold0.pth … fold4.pth\n",
    " │   ├─ oof_logits_tta.npy     ← Cell12\n",
    " │   ├─ best_Ts.npy\n",
    " │   ├─ test_logits.npy        ← Cell13\n",
    " │   ├─ knn_prob_train_k15.npy ← Cell10/14\n",
    " │   └─ knn_prob_test_k15.npy  ← Cell14\n",
    " │   └─ prob_test_blend.npy ← Cell15\n",
    " └─ model_B/          (ex. swin_large)\n",
    "     ├─ best_model_fold0.pth … fold4.pth\n",
    "     ├─ oof_logits_tta.npy\n",
    "     ├─ best_Ts.npy\n",
    "     ├─ test_logits.npy\n",
    "     ├─ knn_prob_train_k15.npy\n",
    "     └─ knn_prob_test_k15.npy\n",
    "     └─ prob_test_blend.npy ← Cell15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────  Cell 16 : 모델 간 앙상블 ───────────────────\n",
    "\"\"\"\n",
    "● MODELS 리스트에 ‘prob_test_blend.npy’ 가 있는 모델 폴더 경로만 추가\n",
    "● OOF 파일(oof_logits_tta.npy)이 존재하는 모델만 가중치 탐색 대상\n",
    "\"\"\"\n",
    "import numpy as np, pandas as pd, os, itertools\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1) 모델 폴더 경로 설정\n",
    "MODEL_DIRS = [\n",
    "    Path(\"/work/model_A\"),   # 5-fold modelA\n",
    "    Path(\"/work/model_B\"),   # 5-fold modelB\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2) 파일 로드\n",
    "probs_test  = {}\n",
    "probs_oof   = {}\n",
    "labels_oof  = None\n",
    "for d in MODEL_DIRS:\n",
    "    probs_test[d.name] = np.load(d / \"prob_test_blend.npy\")\n",
    "    oof_path = d / \"oof_logits_tta.npy\"\n",
    "    if oof_path.exists():\n",
    "        probs_oof[d.name] = np.load(oof_path)\n",
    "        if labels_oof is None:\n",
    "            labels_oof = np.load(d / \"oof_labels.npy\")\n",
    "\n",
    "model_names   = list(probs_test.keys())\n",
    "have_oof      = list(probs_oof.keys())\n",
    "C             = probs_test[model_names[0]].shape[1]\n",
    "\n",
    "print(\"🗂  models :\", model_names)\n",
    "print(\"🗂  with OOF :\", have_oof)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3) 가중치 결정\n",
    "weights = {n:0.0 for n in model_names}\n",
    "\n",
    "if len(have_oof) == 0:                     # OOF 전혀 없으면 동등 가중\n",
    "    for n in weights: weights[n] = 1/len(weights)\n",
    "\n",
    "elif len(have_oof) == 1:                   # OOF 1개뿐 → weight=1\n",
    "    weights[have_oof[0]] = 1.0\n",
    "\n",
    "elif len(have_oof) == 2:                   # OOF 2개 → 1차원 β grid\n",
    "    best_ll, best_b = 1e9, 0.5\n",
    "    betas = np.linspace(0.0,1.0,21)\n",
    "    a,b = have_oof\n",
    "    for β in betas:\n",
    "        mix = β*probs_oof[a] + (1-β)*probs_oof[b]\n",
    "        mix /= mix.sum(1,keepdims=True)\n",
    "        ll = log_loss(labels_oof, mix)\n",
    "        if ll < best_ll: best_ll, best_b = ll, β\n",
    "    weights[a] = best_b\n",
    "    weights[b] = 1-best_b\n",
    "\n",
    "else:                                      # OOF ≥3  → 균등 or 간단 Optuna\n",
    "    for n in have_oof: weights[n] = 1/len(have_oof)\n",
    "\n",
    "# 잔여 가중치를 OOF 없는 모델에 균등 분배\n",
    "residual = 1 - sum(weights.values())\n",
    "no_oof   = [n for n in model_names if n not in have_oof]\n",
    "for n in no_oof:\n",
    "    weights[n] = residual / len(no_oof) if no_oof else 0.0\n",
    "\n",
    "print(\"⚖️  final weights :\", weights)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4) 테스트 확률 합산\n",
    "prob_final = sum(weights[n]*probs_test[n] for n in model_names)\n",
    "prob_final /= prob_final.sum(1, keepdims=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5) sample_submission 작성\n",
    "ss_path = next(Path(\"/work\").rglob(\"sample_submission.csv\"))\n",
    "sub_df  = pd.read_csv(ss_path)\n",
    "sub_df.iloc[:,1:] = prob_final\n",
    "sub_df.to_csv(\"submission.csv\", index=False,\n",
    "              encoding=\"utf-8-sig\", float_format=\"%.9f\")\n",
    "\n",
    "print(\"✅  submission.csv saved :\", sub_df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
