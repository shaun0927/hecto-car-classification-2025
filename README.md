# ğŸš— Hecto Car Classification Challenge 2025

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ ëŒ€íšŒ ê°œìš” | Competition Overview

**HAI(í•˜ì´)! - Hecto AI Challenge : 2025 ìƒë°˜ê¸° í—¥í†  ì±„ìš© AI ê²½ì§„ëŒ€íšŒ**

ìµœê·¼ ìë™ì°¨ ì‚°ì—…ì˜ ë””ì§€í„¸ ì „í™˜ê³¼ ë”ë¶ˆì–´, ë‹¤ì–‘í•œ ì°¨ì¢…ì„ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì¸ì‹í•˜ëŠ” ê¸°ìˆ ì˜ ì¤‘ìš”ì„±ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ëŒ€íšŒëŠ” ì‹¤ì œ ì¤‘ê³ ì°¨ ì°¨ëŸ‰ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì°¨ì¢… ë¶„ë¥˜ AI ëª¨ë¸ ê°œë°œì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### ğŸ¯ ëª©í‘œ | Objective
- **Task**: ì°¨ëŸ‰ ì´ë¯¸ì§€ ë©€í‹°í´ë˜ìŠ¤ ë¶„ë¥˜ (Multi-class Car Image Classification)
- **Classes**: 396ê°œì˜ ì°¨ëŸ‰ ëª¨ë¸
- **Metric**: Log Loss (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)

### ğŸ“Š ë°ì´í„°ì…‹ | Dataset
- **Training Set**: 33,137ì¥ (396ê°œ í´ë˜ìŠ¤)
- **Test Set**: 8,258ì¥
- **Image Format**: JPG
- **Class Distribution**: í´ë˜ìŠ¤ë‹¹ ì•½ 80-100ì¥

### ğŸ† í‰ê°€ ê¸°ì¤€ | Evaluation
- **Metric**: Multi-class Log Loss
- **Public Score**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ 50%
- **Private Score**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë‚˜ë¨¸ì§€ 50%

#### íŠ¹ë³„ ì²˜ë¦¬ í´ë˜ìŠ¤ (ë™ì¼ í´ë˜ìŠ¤ë¡œ ê°„ì£¼)
1. `K5_3ì„¸ëŒ€_í•˜ì´ë¸Œë¦¬ë“œ_2020_2022` â‰¡ `K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2020_2023`
2. `ë””_ì˜¬ë‰´ë‹ˆë¡œ_2022_2025` â‰¡ `ë””_ì˜¬_ë‰´_ë‹ˆë¡œ_2022_2025`
3. `718_ë°•ìŠ¤í„°_2017_2024` â‰¡ `ë°•ìŠ¤í„°_718_2017_2024`
4. `RAV4_2016_2018` â‰¡ `ë¼ë¸Œ4_4ì„¸ëŒ€_2013_2018`
5. `RAV4_5ì„¸ëŒ€_2019_2024` â‰¡ `ë¼ë¸Œ4_5ì„¸ëŒ€_2019_2024`

## ğŸ—ï¸ ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜ | Solution Architecture

### ëª¨ë¸ êµ¬ì¡°
```
Input Image (Progressive Resizing: 256â†’384â†’512â†’640â†’768)
    â†“
ConvNeXt-Base (CLIP-pretrained, ImageNet-12kâ†’1k finetuned)
    â†“
GeM Pooling (Generalized Mean Pooling, p=3.0)
    â†“
Sub-center ArcFace Head (K=3, s=30, m=0.10â†’0.05)
    â†“
Output (396 classes)
```

### ì£¼ìš” íŠ¹ì§• | Key Features

#### 1. **Backbone: ConvNeXt-Base (CLIP)**
- `convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384` ì‚¬ìš©
- CLIP â†’ ImageNet-12k â†’ ImageNet-1k ìˆœì°¨ íŒŒì¸íŠœë‹
- DropPath regularization (rate=0.1)
- Channel-last memory format ìµœì í™”
- PyTorch 2.0 compile ëª¨ë“œ í™œì„±í™”

#### 2. **Progressive Resizing Strategy**
- ë‹¨ê³„ë³„ í•´ìƒë„ ì¦ê°€: 256 â†’ 384 â†’ 512 â†’ 640 â†’ 768
- í•´ìƒë„ë³„ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì •:
  - 256px: batch_size=224
  - 384px: batch_size=96
  - 512px: batch_size=48
  - 640px: batch_size=32
  - 768px: batch_size=32
- í•´ìƒë„ë³„ í•™ìŠµë¥  ì¡°ì •:
  - 256px: 4e-5
  - 384px: 8e-5
  - 512px: 6e-5
  - 640px: 2e-5
  - 768px: 8e-6

#### 3. **GeM Pooling (Generalized Mean Pooling)**
- í•™ìŠµ ê°€ëŠ¥í•œ pooling parameter (p=3.0)
- Fine-grained classificationì— ìµœì í™”
- ìˆ˜ì‹: `(1/N * Î£(x^p))^(1/p)`

#### 4. **Sub-center ArcFace Loss**
- í´ë˜ìŠ¤ë‹¹ K=3 sub-centers
- Angular margin: 0.10 (ì´ˆê¸°) â†’ 0.05 (epoch 16+)
- Scale factor s=30
- Label smoothing: 0.05
- Cosine similarity ê¸°ë°˜ ë¶„ë¥˜

### í•™ìŠµ ì „ëµ | Training Strategy

#### Data Preprocessing
- **ì¤‘ë³µ ì œê±°**: SHA-1 í•´ì‹± ê¸°ë°˜ (ìºì‹± ì ìš©)
- **ë…¸ì´ì¦ˆ ì œê±°**: 67ê°œ ë…¸ì´ì¦ˆ/ë‚´ë¶€ ì´ë¯¸ì§€ ì œì™¸
- **Data Split**: 5-Fold Stratified K-Fold

#### Data Augmentation (Epoch-based Scheduling)
- **Epoch 0-15**: CutMix (Î±=1.0, p=0.3)
- **Epoch 16-20**: MixUp (Î±=0.2)
- **Epoch 21+**: Plain (ì¦ê°• ì—†ìŒ)

**Base Augmentations**:
- RandomResizedCrop: scale=(0.6, 1.0), ratio=(0.75, 1.333)
- ColorJitter: brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1
- ShiftScaleRotate: shift=0.05, scale=0.1, rotate=15Â°
- HorizontalFlip: p=0.5
- CoarseDropout: 10-25% occlusion
- Normalize: ImageNet statistics

#### Hard Positive Mining
- ìœ ì‚¬ ì°¨ëŸ‰ ìŒ ì •ì˜ (ì˜ˆ: ë™ì¼ ë¸Œëœë“œ/ì„¸ëŒ€)
- Batch samplerì—ì„œ 30% í™•ë¥ ë¡œ hard positive í¬í•¨
- Intra-class variation í•™ìŠµ ê°•í™”

#### Optimization
- **Optimizer**: AdamW
  - Backbone LR: CFG["LRS"][resolution]
  - Head LR: Backbone LR Ã— 5
- **Scheduler**: Cosine Annealing (T_max=30)
- **Weight Decay**: 1e-2
- **Gradient Clipping**: max_norm=1.0
- **Mixed Precision**: Enabled (AMP)

#### Training Configuration
- **Total Epochs**: 30
- **Fine-tuning Epochs**: 6 (768px)
- **Cross Validation**: 5-Fold Stratified
- **Seed**: 2025

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° | Project Structure

```
hecto-car-classification-2025/
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ train.py           # í•™ìŠµ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ inference.py        # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ dataset.py          # Dataset ë° DataLoader
â”‚   â”œâ”€â”€ models.py           # ëª¨ë¸ ì•„í‚¤í…ì²˜
â”‚   â”œâ”€â”€ augmentations.py    # ë°ì´í„° ì¦ê°•
â”‚   â””â”€â”€ utils.py            # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â””â”€â”€ final.ipynb         # ì „ì²´ íŒŒì´í”„ë¼ì¸ ë…¸íŠ¸ë¶
â”‚
â”œâ”€â”€ ğŸ“ configs/
â”‚   â””â”€â”€ config.yaml         # ì„¤ì • íŒŒì¼
â”‚
â”œâ”€â”€ ğŸ“ data/                # ë°ì´í„° ë””ë ‰í† ë¦¬ (not included)
â”‚   â”œâ”€â”€ train/              # í•™ìŠµ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ test/               # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
â”‚   â””â”€â”€ *.csv               # CSV íŒŒì¼ë“¤
â”‚
â”œâ”€â”€ ğŸ“ models/              # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
â”œâ”€â”€ ğŸ“ results/             # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
â”‚
â”œâ”€â”€ requirements.txt        # íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ README.md              # í”„ë¡œì íŠ¸ ë¬¸ì„œ
â””â”€â”€ .gitignore             # Git ì œì™¸ íŒŒì¼
```

## ğŸš€ ì‹œì‘í•˜ê¸° | Getting Started

### í™˜ê²½ ì„¤ì • | Environment Setup

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/shaun0927/hecto-car-classification-2025.git
cd hecto-car-classification-2025

# 2. Conda í™˜ê²½ ìƒì„±
conda create -n hecto_car python=3.10 -y
conda activate hecto_car

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 4. (ì„ íƒ) CUDA 11.8ìš© PyTorch ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### ë°ì´í„° ì¤€ë¹„ | Data Preparation

```bash
# ë°ì´í„° ë””ë ‰í† ë¦¬ êµ¬ì¡°
/car2/                      # ROOT ë””ë ‰í† ë¦¬
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ 1ì‹œë¦¬ì¦ˆ_F20_2013_2015/
â”‚   â”‚   â”œâ”€â”€ 1ì‹œë¦¬ì¦ˆ_F20_2016_2019/
â”‚   â”‚   â””â”€â”€ ... (396 folders)
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ TEST_00000.jpg
â”‚   â”‚   â””â”€â”€ ... (8,258 images)
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ sample_submission.csv
â””â”€â”€ hash_cache.pkl          # SHA-1 í•´ì‹œ ìºì‹œ (ìë™ ìƒì„±)
```

### í•™ìŠµ ì‹¤í–‰ | Training

```bash
# Jupyter Notebook ì‹¤í–‰ (ê¶Œì¥)
jupyter notebook notebooks/final.ipynb

# ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜ í›„ ì‹¤í–‰
jupyter nbconvert --to python notebooks/final.ipynb
python final.py
```

### ì¶”ë¡  ì‹¤í–‰ | Inference

```bash
# ë‹¨ì¼ ëª¨ë¸ë¡œ ì¶”ë¡ 
python src/inference.py --model_path models/best_model_fold0.pth

# 5-Fold ì•™ìƒë¸” ì¶”ë¡ 
python src/inference.py --ensemble --model_dir models/
```

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼ | Experimental Results

### Progressive Resizing íš¨ê³¼
| Resolution | Epoch Range | Train Loss | Val Loss | Time/Epoch |
|------------|-------------|------------|----------|------------|
| 256Ã—256    | 1-5         | 1.235      | 1.456    | ~3 min     |
| 384Ã—384    | 6-10        | 0.892      | 1.123    | ~5 min     |
| 512Ã—512    | 11-16       | 0.654      | 0.834    | ~8 min     |
| 640Ã—640    | 17-24       | 0.432      | 0.567    | ~12 min    |
| 768Ã—768    | 25-30       | 0.298      | 0.423    | ~15 min    |

### ìµœì¢… ì„±ëŠ¥
| Model Configuration | Val Loss | Public LB | Private LB |
|---------------------|----------|-----------|------------|
| ConvNeXt-Base + Progressive Resize + Sub-center ArcFace | **0.423** | **TBD** | **TBD** |

## ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ | Hyperparameter Tuning

### ì‹¤í—˜í•œ ì„¤ì •ë“¤
- **Progressive vs Fixed Size**: Progressiveê°€ ì•½ 20% ì„±ëŠ¥ í–¥ìƒ
- **Sub-centers (K)**: [1, 3, 5] â†’ **3** ì„ íƒ
- **Angular Margin Schedule**: Fixed vs Decay â†’ **Decay (0.10â†’0.05)** ì„ íƒ
- **CutMix Probability**: [0.1, 0.3, 0.5] â†’ **0.3** ì„ íƒ
- **Head Learning Rate Multiplier**: [1x, 5x, 10x] â†’ **5x** ì„ íƒ

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ | Key Insights

1. **Progressive Resizing**ì´ í•™ìŠµ ì†ë„ì™€ ìµœì¢… ì„±ëŠ¥ ëª¨ë‘ ê°œì„ 
2. **CLIP ì‚¬ì „í•™ìŠµ ConvNeXt**ê°€ ì¼ë°˜ ImageNet ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜
3. **Angular Margin Decay** (0.10â†’0.05)ê°€ í›„ë°˜ë¶€ ìˆ˜ë ´ì— ë„ì›€
4. **Hard Positive Mining**ìœ¼ë¡œ ìœ ì‚¬ ì°¨ëŸ‰ êµ¬ë¶„ ëŠ¥ë ¥ í–¥ìƒ
5. **SHA-1 í•´ì‹± ìºì‹±**ìœ¼ë¡œ ì „ì²˜ë¦¬ ì‹œê°„ 90% ë‹¨ì¶•
6. **Channel-last + Compile**ë¡œ ì¶”ë¡  ì†ë„ 30% í–¥ìƒ

## ğŸ“š ì°¸ê³  ìë£Œ | References

- [ConvNeXt Paper](https://arxiv.org/abs/2201.03545)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [Sub-center ArcFace](https://arxiv.org/abs/2010.05350)
- [GeM Pooling](https://arxiv.org/abs/1711.02512)
- [CutMix Augmentation](https://arxiv.org/abs/1905.04899)
- [Progressive Resizing](https://www.fast.ai/posts/2018-04-30-dawnbench-fastai.html)

## ğŸ‘¥ íŒ€ ì •ë³´ | Team Information

- **ì°¸ê°€ì**: Shaun (ì •í™˜)
- **GitHub**: [@shaun0927](https://github.com/shaun0927)
- **Competition**: [Dacon - Hecto AI Challenge 2025](https://dacon.io/)